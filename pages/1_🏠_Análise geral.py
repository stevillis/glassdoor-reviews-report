import math
import warnings
from collections import Counter

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import streamlit as st
from PIL import Image
from wordcloud import WordCloud

from app_messages import AppMessages
from report_config import ReportConfig
from utils import (
    ROLE_GROUPS,
    STOPWORDS,
    TRANSLATION_TABLE_SPECIAL_CHARACTERS,
    get_top_ngrams,
    load_reviews_df,
    set_companies_raking_to_session,
)


def introduction():
    st.subheader("Introdu√ß√£o")

    st.markdown(
        """
    Se voc√™ √© um profissional de Tecnologia da Informa√ß√£o (TI) e est√° buscando
    a primeira experi√™ncia ou mesmo uma recoloca√ß√£o, j√° deve ter analisado o
    perfil de algumas empresas para entender se estas seriam um bom fit para
    voc√™. Plataformas como o **Glassdoor** s√£o uma boa fonte para entender como
    ex-funcion√°rios e funcion√°rios atuais avaliam as empresas. Mas analisar
    centenas ou milhares de avalia√ß√µes nessas plataformas pode ser
    um desafio enorme.

    Pensando em resolver um problema pessoal de entender como empresas de TI
    de Cuiab√° eram avaliadas no Glassdoor e tamb√©m ajudar profissionais com o
    mesmo desafio, treinei um Modelo de [Intelig√™ncia Artificial (IA)](https://pt.wikipedia.org/wiki/Intelig%C3%AAncia_artificial)
    baseado na t√©cnica de [Transfer Learning](https://pt.wikipedia.org/wiki/Aprendizado_por_transfer%C3%AAncia)
    com [BERTimbau](https://neuralmind.ai/bert/). O Modelo foi treinado para
    classificar as avalia√ß√µes da plataforma em tr√™s classes: **Positivo**,
    **Negativo** e **Neutro**. Os detalhes de **treinamento e avalia√ß√£o do
    Modelo** est√£o dispon√≠veis no menu [üß† Treinamento do Modelo](./Treinamento_do_Modelo).
    Voc√™ pode utilizar o modelo acessando o [Hugging Face Spaces](https://huggingface.co/spaces/stevillis/bertimbau-finetuned-glassdoor-reviews).

    Ao explorar as se√ß√µes subsequentes, voc√™ poder√° entender melhor como as
    empresas de TI em Cuiab√° s√£o percebidas pelos funcion√°rios e
    ex-funcion√°rios. As an√°lises dos dados gerais busca responder as seguintes
    quest√µes:
    - Quais as empresas com melhor rela√ß√£o entre avalia√ß√µes positivas e
    negativas? E quais seriam as piores nesse crit√©rio?
    - Ao longo do tempo, houve alguma mudan√ßa na quantidade de avalia√ß√µes por
    sentimento?
    - Qual a distribui√ß√£o de sentimentos de acordo com a nota atribu√≠da
    para cada avalia√ß√£o?
    - Avalia√ß√µes de profissionais de TI s√£o predominantes?
    - Quais as palavras mais frequentes nas avalia√ß√µes?
    - Quais palavras aparecem com mais frequ√™ncia juntas?
    """,
        unsafe_allow_html=True,
    )


@st.cache_data
def positive_reviews_ranking():
    st.subheader("Ranking de avalia√ß√µes positivas por empresa")

    st.markdown(
        """
    Este gr√°fico ilustra as 5 empresas que apresentam **n√∫mero de
    avalia√ß√µes positivas superior ao de avalia√ß√µes negativas**. Para garantir
    a relev√¢ncia dos dados, **foram consideradas apenas as empresas com pelo
    menos 21 avalia√ß√µes**, que representa a metade da mediana de avalia√ß√µes de
    todas as empresas analisadas.
    """
    )

    top_positive_companies_df = st.session_state.get("top_positive_companies_df")

    fig, ax = plt.subplots(1, figsize=(10, 8))

    sns.barplot(
        data=top_positive_companies_df,
        x="sentiment_count",
        y="company",
        hue="sentiment_plot",
        palette=[
            ReportConfig.POSITIVE_SENTIMENT_COLOR,
            ReportConfig.NEGATIVE_SENTIMENT_COLOR,
            ReportConfig.NEUTRAL_SENTIMENT_COLOR,
        ],
        ax=ax,
        width=0.9,
        orient="h",
    )

    # Annotates
    for p in ax.patches:
        ax.annotate(
            text=f"{p.get_width():.0f}",
            xy=(p.get_width(), (p.get_y() + p.get_height() / 2)),
            ha="center",
            va="center",
            fontsize=10,
            color="black",
            xytext=(10, 0),
            textcoords="offset points",
        )

    # Axes config
    ax.set_xlabel("")

    ax.set_xticks([])

    ax.set_ylabel("")

    ax.set_title(
        label="",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.1,
    )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)

    positive_patch = plt.Rectangle(
        (0, 0), 1, 1, fc=ReportConfig.POSITIVE_SENTIMENT_COLOR
    )
    negative_patch = plt.Rectangle(
        (0, 0), 1, 1, fc=ReportConfig.NEGATIVE_SENTIMENT_COLOR
    )
    neutral_patch = plt.Rectangle((0, 0), 1, 1, fc=ReportConfig.NEUTRAL_SENTIMENT_COLOR)

    ax.legend(
        # title="Sentimento",
        handles=[positive_patch, negative_patch, neutral_patch],
        labels=ReportConfig.PLOT_SENTIMENT_LABELS,
        bbox_to_anchor=(0.5, 1.1),
        loc="upper center",
        edgecolor="1",
        ncols=3,
    )

    return fig


@st.cache_data
def negative_reviews_ranking():
    st.subheader("Ranking de avalia√ß√µes negativas por empresa")

    st.markdown(
        """
    Este gr√°fico mostra as empresas que apresentam **n√∫mero de
    avalia√ß√µes negativas superior ao de avalia√ß√µes positivas**, seguindo
    os mesmos crit√©rios do gr√°fico anterior.
    """
    )

    top_negative_companies_df = st.session_state.get("top_negative_companies_df")

    fig, ax = plt.subplots(1, figsize=(10, 8))

    sns.barplot(
        data=top_negative_companies_df,
        x="sentiment_count",
        y="company",
        hue="sentiment_plot",
        palette=[
            ReportConfig.POSITIVE_SENTIMENT_COLOR,
            ReportConfig.NEGATIVE_SENTIMENT_COLOR,
            ReportConfig.NEUTRAL_SENTIMENT_COLOR,
        ],
        ax=ax,
        width=0.9,
        orient="h",
    )

    # Annotates
    for p in ax.patches:
        ax.annotate(
            text=f"{p.get_width():.0f}",
            xy=(p.get_width(), (p.get_y() + p.get_height() / 2)),
            ha="center",
            va="center",
            fontsize=10,
            color="black",
            xytext=(10, 0),
            textcoords="offset points",
        )

    # Axes config
    ax.set_xlabel("")

    ax.set_xticks([])

    ax.set_ylabel("")

    ax.set_title(
        label="",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.1,
    )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)

    positive_patch = plt.Rectangle(
        (0, 0), 1, 1, fc=ReportConfig.POSITIVE_SENTIMENT_COLOR
    )
    negative_patch = plt.Rectangle(
        (0, 0), 1, 1, fc=ReportConfig.NEGATIVE_SENTIMENT_COLOR
    )
    neutral_patch = plt.Rectangle((0, 0), 1, 1, fc=ReportConfig.NEUTRAL_SENTIMENT_COLOR)

    ax.legend(
        # title="Sentimento",
        handles=[positive_patch, negative_patch, neutral_patch],
        labels=ReportConfig.PLOT_SENTIMENT_LABELS,
        bbox_to_anchor=(0.5, 1.1),
        loc="upper center",
        edgecolor="1",
        ncols=3,
    )

    return fig


def company_analisys():
    st.subheader("Sentimentos das Avalia√ß√µes por Empresa")

    st.markdown(
        """
    A visualiza√ß√£o da distribui√ß√£o de avalia√ß√µes e emo√ß√µes em todas as
    empresas permite uma compara√ß√£o r√°pida e uma vis√£o abrangente do panorama
    geral.
    """
    )

    reviews_df = load_reviews_df()

    fig, ax = plt.subplots(1, figsize=(12, 6))
    sns.countplot(
        data=reviews_df,
        x="company",
        hue="sentiment",
        order=reviews_df["company"].value_counts().index,
        ax=ax,
        palette=ReportConfig.SENTIMENT_PALETTE,
    )

    for p in ax.patches:
        ax.annotate(
            f"{int(p.get_height())}",
            (p.get_x() + p.get_width() / 2.0, p.get_height()),
            ha="center",
            va="center",
            fontsize=6,
            color="black",
            xytext=(0, 5),
            textcoords="offset points",
        )

    sns.despine(bottom=False, left=True)

    plt.title(
        "Sentimentos das Avalia√ß√µes por Empresa",
        fontdict={
            "weight": "bold",
            "size": ReportConfig.CHART_TITLE_FONT_SIZE,
        },
    )

    plt.xlabel("")
    plt.ylabel("")

    plt.xticks(rotation=45, ha="right")
    plt.yticks([])

    plt.legend(title="Sentimento", labels=ReportConfig.SENTIMENT_DICT.values())

    st.pyplot(fig)


@st.cache_data
def sentiment_reviews_along_time():
    st.subheader("Sentimento das avalia√ß√µes ao longo do tempo")

    st.markdown(
        """
     Este gr√°fico revela que as avalia√ß√µes positivas sempre foram mais
     frequentes do que as negativas e neutras. O ano de 2022 destacou-se como
     o per√≠odo com o maior n√∫mero total de avalia√ß√µes, apresentando tamb√©m a
     maior disparidade entre as avalia√ß√µes positivas e negativas.
    """,
        unsafe_allow_html=True,
    )

    reviews_df = load_reviews_df()

    reviews_df["review_date"] = pd.to_datetime(
        reviews_df["review_date"], format="%Y-%m-%d"
    )
    reviews_df["year"] = reviews_df["review_date"].dt.year

    sentiment_counts = (
        reviews_df.groupby(["year", "sentiment"]).size().reset_index(name="count")
    )

    fig, ax = plt.subplots(1, figsize=(12, 6))
    sns.lineplot(
        data=sentiment_counts,
        x="year",
        y="count",
        hue="sentiment",
        palette=ReportConfig.SENTIMENT_PALETTE,
        ax=ax,
    )

    # Annotations for number of reviews per sentiment
    years_unique = sentiment_counts["year"].unique()
    for year in years_unique:
        year_counts = sentiment_counts[sentiment_counts["year"] == year][
            "count"
        ].tolist()

        neutral_counts, positive_counts, negative_counts = (year_counts + [None] * 3)[
            :3
        ]

        if neutral_counts:
            ax.text(
                x=year,
                y=neutral_counts - 8,
                s=f"{neutral_counts}",
                ha="center",
                color=ReportConfig.NEUTRAL_SENTIMENT_COLOR,
            )

        if positive_counts:
            ax.text(
                x=year,
                y=positive_counts + 8,
                s=f"{positive_counts}",
                ha="center",
                color=ReportConfig.POSITIVE_SENTIMENT_COLOR,
            )

        if negative_counts:
            ax.text(
                x=year,
                y=negative_counts - 8,
                s=f"{negative_counts}",
                ha="center",
                color=ReportConfig.NEGATIVE_SENTIMENT_COLOR,
            )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    # ax.spines["bottom"].set_visible(False)

    ax.set_xlabel("Ano")
    ax.set_ylabel("Quantidade de avalia√ß√µes")

    ax.set_title(
        label="",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.1,
    )

    handles, labels = ax.get_legend_handles_labels()
    order_map = {label: handle for handle, label in zip(handles, labels)}
    handles = [order_map[sentiment] for sentiment in ReportConfig.PLOT_SENTIMENT_VALUES]

    plt.legend(
        # title="Sentimento",
        handles=handles,
        labels=ReportConfig.PLOT_SENTIMENT_LABELS,
        bbox_to_anchor=(0.5, 1.1),
        loc="upper center",
        edgecolor="1",
        ncols=3,
    )

    return fig


@st.cache_data
def rating_star_analysis():
    reviews_df = load_reviews_df()

    st.subheader("Distribui√ß√£o de sentimentos por quantidade de estrelas")

    st.markdown(
        """
        - As **avalia√ß√µes de 1 a 3 estrelas** apresentam **sentimento
        predominantemente negativo**.
        - Por outro lado, as **avalia√ß√µes de 4 estrelas** mostram uma
        **distribui√ß√£o equilibrada entre sentimentos positivos e negativos**.
        - J√° as **avalia√ß√µes de 5 estrelas** s√£o
        **majoritariamente positivas**, destacando-se tamb√©m um
        **n√∫mero significativo de avalia√ß√µes neutras**.

        Essa predomin√¢ncia de avalia√ß√µes neutras em avalia√ß√µes de 5 estrelas
        pode ser atribu√≠da √† exig√™ncia ao usu√°rio do Glassdoor de preencher as
        se√ß√µes *Pr√≥s* e *Contras* ao avaliarem uma empresa. Em diversas
        avalia√ß√µes, os usu√°rios n√£o encontram aspectos negativos a serem
        mencionados na se√ß√£o *Contras*, resultando em coment√°rios neutros como
        `N√£o h√° nada a ser apontado` ou `N√£o tenho nada a reclamar`.
    """
    )

    filtered_df = reviews_df[
        [
            "company",
            "employee_role",
            "employee_detail",
            "review_text",
            "review_date",
            "star_rating",
            "sentiment_plot",
            "sentiment_label",
        ]
    ]

    filtered_df.reset_index(drop=True, inplace=True)

    if len(filtered_df) > 0:
        sentiment_counts = (
            filtered_df.groupby(["star_rating", "sentiment_plot"])
            .size()
            .reset_index(name="count")
        )

        fig, ax = plt.subplots(1, figsize=(10, 6))

        bars = sns.barplot(
            data=sentiment_counts,
            x="star_rating",
            y="count",
            hue="sentiment_plot",
            ax=ax,
            palette=[
                ReportConfig.POSITIVE_SENTIMENT_COLOR,
                ReportConfig.NEGATIVE_SENTIMENT_COLOR,
                ReportConfig.NEUTRAL_SENTIMENT_COLOR,
            ],
        )

        for p in bars.patches:
            height = p.get_height()
            if math.isnan(height):
                height = 0.0

            bars.annotate(
                text=f"{int(height)}",
                xy=(p.get_x() + p.get_width() / 2.0, height),
                ha="center",
                va="center",
                fontsize=10,
                color="black",
                xytext=(0, 5),
                textcoords="offset points",
            )

        ax.set_title(
            label="",
            fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
            y=1.1,
        )

        ax.set_xlabel("")
        ax.set_xticklabels(
            ["\u2605" * int(x) for x in sentiment_counts["star_rating"].unique()]
        )

        ax.set_yticks([])
        ax.set_ylabel("")

        ax.spines["top"].set_visible(False)
        ax.spines["right"].set_visible(False)
        ax.spines["left"].set_visible(False)

        positive_patch = plt.Rectangle(
            (0, 0), 1, 1, fc=ReportConfig.POSITIVE_SENTIMENT_COLOR
        )
        negative_patch = plt.Rectangle(
            (0, 0), 1, 1, fc=ReportConfig.NEGATIVE_SENTIMENT_COLOR
        )
        neutral_patch = plt.Rectangle(
            (0, 0), 1, 1, fc=ReportConfig.NEUTRAL_SENTIMENT_COLOR
        )

        ax.legend(
            # title="Sentimento",
            handles=[positive_patch, negative_patch, neutral_patch],
            labels=ReportConfig.PLOT_SENTIMENT_LABELS,
            bbox_to_anchor=(0.5, 1.1),
            loc="upper center",
            edgecolor="1",
            ncols=3,
        )

        return fig

    return None


@st.cache_data
def employee_role_analysis():
    reviews_df = load_reviews_df()

    st.subheader("Distribui√ß√£o de sentimentos por grupo de funcion√°rios")

    st.markdown(
        """
        Este gr√°fico revela que as **avalia√ß√µes positivas s√£o predominantes**,
        independentemente do grupo de funcion√°rios. A maioria das
        avalia√ß√µes prov√©m de profissionais de outras √°reas, com destaque para
        os seguintes dados:

        - Cerca de **64% das avalia√ß√µes** s√£o provenientes de profissionais de
        √°reas n√£o relacionadas √† TI.
        - Os **profissionais de TI representam cerca de 25%** do total de
        avalia√ß√µes.
        - Aproximadamente **11% das avalia√ß√µes** foram emitidas por
        profissionais que optaram por n√£o revelar seus cargos.
    """
    )

    filtered_df = reviews_df[
        [
            "company",
            "employee_role",
            "employee_detail",
            "review_text",
            "review_date",
            "star_rating",
            "sentiment_plot",
            "sentiment_label",
            "role_group",
        ]
    ]

    filtered_df.reset_index(drop=True, inplace=True)

    if len(filtered_df) > 0:
        sentiment_counts = (
            reviews_df.groupby(["role_group", "sentiment_plot"])
            .size()
            .reset_index(name="sentiment_count")
        )

        fig, ax = plt.subplots(1, figsize=(10, 6))

        sns.barplot(
            data=sentiment_counts,
            x="sentiment_count",
            y="role_group",
            hue="sentiment_plot",
            palette=[
                ReportConfig.POSITIVE_SENTIMENT_COLOR,
                ReportConfig.NEGATIVE_SENTIMENT_COLOR,
                ReportConfig.NEUTRAL_SENTIMENT_COLOR,
            ],
            ax=ax,
            width=0.9,
            orient="h",
        )

        for p in ax.patches:
            ax.annotate(
                text=f"{p.get_width():.0f}",
                xy=(p.get_width(), (p.get_y() + p.get_height() / 2)),
                ha="center",
                va="center",
                fontsize=10,
                color="black",
                xytext=(10, 0),
                textcoords="offset points",
            )

        ax.set_title(
            label="",
            fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
            y=1.1,
        )

        ax.set_xlabel("")
        ax.set_xticks([])

        ax.set_ylabel("")
        ax.set_yticklabels(
            [ROLE_GROUPS[group] for group in sentiment_counts["role_group"].unique()]
        )

        ax.spines["top"].set_visible(False)
        ax.spines["right"].set_visible(False)
        ax.spines["bottom"].set_visible(False)

        positive_patch = plt.Rectangle(
            (0, 0), 1, 1, fc=ReportConfig.POSITIVE_SENTIMENT_COLOR
        )
        negative_patch = plt.Rectangle(
            (0, 0), 1, 1, fc=ReportConfig.NEGATIVE_SENTIMENT_COLOR
        )
        neutral_patch = plt.Rectangle(
            (0, 0), 1, 1, fc=ReportConfig.NEUTRAL_SENTIMENT_COLOR
        )

        ax.legend(
            # title="Sentimento",
            handles=[positive_patch, negative_patch, neutral_patch],
            labels=ReportConfig.PLOT_SENTIMENT_LABELS,
            bbox_to_anchor=(0.5, 1.1),
            loc="upper center",
            edgecolor="1",
            ncols=3,
        )

        return fig

    return None


@st.cache_data
def wordcloud_analysis():
    st.subheader("Nuvem de Palavras")

    st.markdown(
        """
    A Nuvem de Palavras ([Word Cloud](https://techner.com.br/glossario/o-que-e-word-cloud/ "Word Cloud"))
    **√© uma representa√ß√£o visual que ilustra as palavras mais frequentemente
    utilizadas no conjunto de avalia√ß√µes**. Neste gr√°fico, as palavras
    aparecem em tamanhos variados, refletindo sua frequ√™ncia de uso: quanto
    maior a palavra, mais vezes ela foi mencionada nas avalia√ß√µes. √â
    importante ressaltar que as *stopwords*, que s√£o palavras comuns e
    geralmente sem significado relevante para a an√°lise (como "e", "a", "o",
    "de") foram exclu√≠das desta visualiza√ß√£o.

    A Nuvem de Palavras a seguir mostra as 50 palavras mais frequentes nas
    avalia√ß√µes e permite a identifica√ß√£o r√°pida dos t√≥picos mais relevantes,
    onde `empresa` e `trabalho` s√£o visivelmente as palavras mais comuns.
    """
    )

    reviews_df = load_reviews_df()
    review_text = reviews_df["review_text"].str.split().values.tolist()
    corpus = [word for i in review_text for word in i]

    non_stopwords_corpus = []
    for word in corpus:
        word_lower = word.lower()
        cleaned_word = word_lower.translate(TRANSLATION_TABLE_SPECIAL_CHARACTERS)
        if cleaned_word and cleaned_word not in STOPWORDS:
            non_stopwords_corpus.append(cleaned_word)

    counter = Counter(non_stopwords_corpus)
    most_common_words = counter.most_common(n=50)

    mask = np.array(Image.open("./img/black_jaguar.jpg"))
    wordcloud = WordCloud(
        background_color="white",
        mask=mask,
        random_state=ReportConfig.RANDOM_SEED,
        # max_words=50,
        width=1024,
        height=768,
        contour_color="black",
        contour_width=1,
    )

    fig, ax = plt.subplots(1, figsize=(10, 6))
    plt.axis("off")

    ax.imshow(wordcloud.generate_from_frequencies(dict(most_common_words)))

    return fig


@st.cache_data
def most_common_words_analysis():
    st.subheader("Top 10 palavras mais frequentes nas avalia√ß√µes")

    st.markdown(
        """
        Embora a Nuvem de Palavras ofere√ßa uma vis√£o geral interessante das
        palavras mais utilizadas nas avalia√ß√µes, ela pode n√£o ser a melhor
        op√ß√£o para destacar de forma clara e precisa a palavra mais frequente.
        Para complementar essa an√°lise e oferecer uma vis√£o mais quantitativa,
        √© apresentado um gr√°fico com as 10 palavras mais utilizadas nas
        avalia√ß√µes analisadas, junto como suas respectivas frequ√™ncias.

        Este gr√°fico segue os mesmos crit√©rios da Nuvem de Palavras,
        garantindo que as palavras selecionadas sejam relevantes e
        significativas.
    """
    )

    reviews_df = load_reviews_df()
    review_text = reviews_df["review_text"].str.split().values.tolist()
    corpus = [word for i in review_text for word in i]

    non_stopwords_corpus = []
    for word in corpus:
        word_lower = word.lower()
        cleaned_word = word_lower.translate(TRANSLATION_TABLE_SPECIAL_CHARACTERS)
        if cleaned_word and cleaned_word not in STOPWORDS:
            non_stopwords_corpus.append(cleaned_word)

    counter = Counter(non_stopwords_corpus)
    most_common_words = counter.most_common(n=10)

    words, counts = zip(*most_common_words)  # Unzip the words and counts
    most_common_words_df = pd.DataFrame({"words": words, "counts": counts})

    fig, ax = plt.subplots(1, figsize=(10, 8))

    sns.barplot(
        data=most_common_words_df,
        x="counts",
        y="words",
        ax=ax,
        width=0.9,
        orient="h",
    )

    # Annotates
    for p in ax.patches:
        ax.annotate(
            text=f"{p.get_width():.0f}",
            xy=(p.get_width(), (p.get_y() + p.get_height() / 2)),
            ha="center",
            va="center",
            fontsize=10,
            color="white",
            xytext=(-15, 0),
            textcoords="offset points",
        )

    # Axes config
    ax.set_xlabel("")

    ax.set_xticks([])

    ax.set_ylabel("")

    ax.set_title(
        label="",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.0,
    )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)

    return fig


@st.cache_data
def ngram_analysis():
    st.subheader("Top 10 N-Grams mais frequentes nas avalia√ß√µes")

    st.markdown(
        """
    Embora o gr√°fico de palavras mais frequentes forne√ßa uma vis√£o inicial
    sobre os termos mais utilizados nas avalia√ß√µes, ele n√£o captura a riqueza
    dos contextos em que essas palavras aparecem. Palavras isoladas podem ter
    significados variados e n√£o revelam como elas se combinam para formar
    ideias ou sentimentos mais complexos. Por exemplo, a palavra `crescimento`
    pode aparecer frequentemente, mas sem o contexto, como em `oportunidade de
    crescimento`, seu significado pode ser amb√≠guo.

    Os [N-Gramas](https://pt.wikipedia.org/wiki/N-grama) s√£o sequ√™ncias
    cont√≠guas de "n" itens (palavras ou caracteres) e s√£o essenciais para uma
    an√°lise mais profunda, pois permitem identificar padr√µes e temas
    recorrentes nas avalia√ß√µes. Ao considerar as combina√ß√µes de palavras, √©
    poss√≠vel entender melhor as percep√ß√µes dos funcion√°rios e os aspectos mais
    relevantes de suas experi√™ncias.

    Ao analisar os Top 10 Trigramas mais frequentes, conclui-se que as
    combina√ß√µes de palavras mais frequentes foram: `ambiente de trabalho`,
    `plano de carreira` e `plano de sa√∫de`.
    """
    )

    reviews_df = load_reviews_df()

    review_text = reviews_df["review_text"]

    ngrams = get_top_ngrams(review_text, ngram_range=(3, 3), top_n=10)

    x, y = map(list, zip(*ngrams))

    fig, ax = plt.subplots(1, figsize=(10, 8))

    sns.barplot(
        x=y,
        y=x,
        ax=ax,
        width=0.9,
        orient="h",
    )

    # Annotates
    for p in ax.patches:
        ax.annotate(
            text=f"{p.get_width():.0f}",
            xy=(p.get_width(), (p.get_y() + p.get_height() / 2)),
            ha="center",
            va="center",
            fontsize=11,
            color="white",
            xytext=(-15, 0),
            textcoords="offset points",
        )

    # Axes config
    ax.set_xlabel("")

    ax.set_xticks([])

    ax.set_ylabel("")

    ax.set_title(
        label="",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.0,
    )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)

    return fig


def conclusion():
    st.subheader("Conclus√£o")

    st.markdown(
        """
    As **avalia√ß√µes positivas** frequentemente mencionam temas como **ambiente
    de trabalho**, **plano de sa√∫de** e **oportunidade de crescimento**,
    enquanto as **avalia√ß√µes negativas** destacam preocupa√ß√µes com **plano de
    carreira**, **sal√°rio abaixo do mercado** e, em alguns casos, o **plano de
    sa√∫de**. As **avalia√ß√µes neutras**, embora menos frequentes, sugerem que
    muitos colaboradores **n√£o encontraram aspectos negativos a serem
    destacados**, indicando uma satisfa√ß√£o geral com suas experi√™ncias.

    Al√©m disso, a an√°lise temporal revelou que **as avalia√ß√µes positivas sempre
    foram predominantes em rela√ß√£o as demais**. Esta an√°lise tamb√©m mostrou que
    houve um grande aumento no n√∫mero de avalia√ß√µes entre 2020 e 2022, per√≠odo
    da Pandemia de Covid-19, onde as empresas contrataram mais.

    **A reputa√ß√£o positiva, refletida nas avalia√ß√µes, pode ser um diferencial
    decisivo na escolha de uma empresa por candidatos qualificados**,
    impactando diretamente o sucesso e a competitividade no mercado.

    #### Tecnologias e ferramentas usadas

    | **Categoria**                     | **Tecnologia/Ferramenta**                                                                                                                                           |
    |-----------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|
    | Extra√ß√£o de Dados                 | ![Selenium](https://img.shields.io/badge/-selenium-%43B02A?style=for-the-badge&logo=selenium&logoColor=white) BeautifulSoup                           |
    | Manipula√ß√£o e An√°lise de Dados    | ![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54) ![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white) ![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white) |
    | Treinamento e Avalia√ß√£o do Modelo | ![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white) ![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white) |
    | Visualiza√ß√£o de Dados             | ![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black) ![Streamlit](https://img.shields.io/badge/Streamlit-%23FE4B4B.svg?style=for-the-badge&logo=streamlit&logoColor=white) Seaborn |
    | Versionamento                     | ![Git](https://img.shields.io/badge/git-%23F05033.svg?style=for-the-badge&logo=git&logoColor=white) ![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white) |
    | Ambiente de Desenvolvimento       | ![Visual Studio Code](https://img.shields.io/badge/Visual%20Studio%20Code-0078d7.svg?style=for-the-badge&logo=visual-studio-code&logoColor=white) ![Kaggle](https://img.shields.io/badge/Kaggle-035a7d?style=for-the-badge&logo=kaggle&logoColor=white) Google Colab |

    """,
        unsafe_allow_html=True,
    )


if __name__ == "__main__":
    warnings.filterwarnings("ignore", "use_inf_as_na")

    st.set_page_config(
        page_title="Home",
        page_icon=":house:",
    )

    st.markdown(
        ReportConfig.CUSTOM_CSS,
        unsafe_allow_html=True,
    )

    st.sidebar.warning(AppMessages.WARNING_PLOT_NOT_WORKING)

    st.header(
        "An√°lise de sentimento em avalia√ß√µes no Glassdoor: Um estudo sobre empresas de Tecnologia da Informa√ß√£o em Cuiab√°"
    )

    reviews_df = load_reviews_df()
    set_companies_raking_to_session(
        reviews_df
    )  # TODO: maybe this can be done in load_reviews_df

    introduction()

    # company_analisys()

    with st.container():
        st.pyplot(positive_reviews_ranking())

    with st.container():
        st.pyplot(negative_reviews_ranking())
        st.markdown(
            """
        O ranking completo de avalia√ß√µes por empresa pode ser visualizado no
        menu <a target="_self" href="./Ranking_geral_de_avalia√ß√µes">ü•áRanking
        geral de avalia√ß√µes</a>.
        """,
            unsafe_allow_html=True,
        )

    with st.container():
        st.pyplot(sentiment_reviews_along_time())
        st.markdown(
            """
        As avalia√ß√µes ao longo do tempo por empresa podem ser visualizadas no
        menu <a target="_self" href="./Avalia√ß√µes_ao_longo_do_tempo">
        üìâAvalia√ß√µes ao longo do tempo</a>.

        <br/>
        """,
            unsafe_allow_html=True,
        )

    with st.container():
        fig = rating_star_analysis()
        if fig:
            st.pyplot(fig)
        else:
            st.error(
                AppMessages.ERROR_EMPTY_DATAFRAME,
                icon="üö®",
            )

        st.markdown(
            """
            A distribui√ß√£o de sentimentos por quantidade de estrelas para cada
            empresa pode ser visualizada no menu
            <a target="_self" href="./Avalia√ß√µes_por_quantidade_de_estrelas">
            üìäAvalia√ß√µes por quantidade de estrelas</a>.
        """,
            unsafe_allow_html=True,
        )

    with st.container():
        fig = rating_star_analysis()
        if fig:
            st.pyplot(fig)
        else:
            st.error(
                AppMessages.ERROR_EMPTY_DATAFRAME,
                icon="üö®",
            )

    with st.container():
        fig = employee_role_analysis()
        if fig:
            st.pyplot(fig)
        else:
            st.error(
                AppMessages.ERROR_EMPTY_DATAFRAME,
                icon="üö®",
            )

        st.markdown(
            """
            A distribui√ß√£o de sentimentos por grupo de funcion√°rios para cada
            empresa pode ser visualizada no menu
            <a target="_self" href="./Avalia√ß√µes_por_grupo_de_funcion√°rios">
            üìäAvalia√ß√µes por grupo de funcion√°rios</a>.
        """,
            unsafe_allow_html=True,
        )

    with st.container():
        st.pyplot(wordcloud_analysis())
        st.markdown(
            """
        A Word Cloud de avalia√ß√µes por sentimento e por empresa pode ser
        visualizada no menu
        <a target="_self" href="./Nuvem_de_Palavras_por_empresa">‚òÅÔ∏èNuvem de Palavras por empresa</a>.
        """,
            unsafe_allow_html=True,
        )

    with st.container():
        st.pyplot(most_common_words_analysis())
        st.markdown(
            """
        As Top 10 palavras mais frequentes nas avalia√ß√µes por empresa e por
        sentimento podem ser visualizadas no menu
        <a target="_self" href="./Top_10_palavras_mais_usadas">üìäTop 10 palavras mais frequentes</a>.
        """,
            unsafe_allow_html=True,
        )

    with st.container():
        st.pyplot(ngram_analysis())
        st.markdown(
            """
        Os Top 10 N-Grams mais frequentes nas avalia√ß√µes de cada empresa pode
        ser visualizado no menu <a target="_self" href="./NGrams">üî†NGrams</a>.
    """,
            unsafe_allow_html=True,
        )

    with st.container():
        conclusion()
