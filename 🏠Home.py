import math
import warnings
from collections import Counter

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import streamlit as st
from sklearn.feature_extraction.text import CountVectorizer
from wordcloud import WordCloud

from app_messages import AppMessages
from report_config import ReportConfig
from utils import (
    STOPWORDS,
    TRANSLATION_TABLE_SPECIAL_CHARACTERS,
    create_predicted_sentiment_plot,
    get_ranking_positive_negative_companies,
)


def introduction():
    st.markdown(
        """
   As avalia√ß√µes de funcion√°rios no Glassdoor proporcionam uma vis√£o valiosa
   sobre a cultura e o ambiente de trabalho de uma empresa. No contexto do
   setor de Tecnologia, entender as emo√ß√µes expressas nessas avalia√ß√µes √©
   crucial para atrair e reter talentos.

   Al√©m disso, essas percep√ß√µes podem  servir como base para reestrutura√ß√µes
   necess√°rias, especialmente em resposta a coment√°rios negativos. Ao
   valorizar o feedback dos colaboradores, as organiza√ß√µes podem n√£o apenas
   melhorar seu ambiente interno, mas tamb√©m garantir um caminho s√≥lido para o
   sucesso a longo prazo.

    Esse trabalho mostra uma **an√°lise das emo√ß√µes expressas nas avalia√ß√µes
    no Glassdoor de 22 empresas de Tecnologia de Cuiab√°**, com dados de **05 de
    outubro de 2014 a 16 de mar√ßo de 2024** e um total de **2532 avalia√ß√µes**.
    Para isso, foi treinado um Modelo de [Intelig√™ncia Artificial (IA)](https://pt.wikipedia.org/wiki/Intelig%C3%AAncia_artificial)
    baseado na t√©cnica de [Transfer Learning](https://pt.wikipedia.org/wiki/Aprendizado_por_transfer%C3%AAncia)
    com [BERTimbau](https://neuralmind.ai/bert/).

    Os detalhes de treinamento e avalia√ß√£o do Modelo podem ser acessados no
    menu
    <a target="_self" href="./Treinamento_do_Modelo">üß†Treinamento do Modelo</a>.

    #### Tecnologias e ferramentas usadas

    | **Categoria**                     | **Ferramentas e Tecnologias**                                                                                                                                           |
    |-----------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|
    | Extra√ß√£o de Dados                 | ![Selenium](https://img.shields.io/badge/-selenium-%43B02A?style=for-the-badge&logo=selenium&logoColor=white) BeautifulSoup                           |
    | Manipula√ß√£o e An√°lise de Dados    | ![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54) ![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white) ![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white) |
    | Treinamento e Avalia√ß√£o do Modelo | ![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white) ![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white) |
    | Visualiza√ß√£o de Dados             | ![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black) ![Streamlit](https://img.shields.io/badge/Streamlit-%23FE4B4B.svg?style=for-the-badge&logo=streamlit&logoColor=white) Seaborn |
    | Versionamento                     | ![Git](https://img.shields.io/badge/git-%23F05033.svg?style=for-the-badge&logo=git&logoColor=white) ![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white) |
    | Ambiente de Desenvolvimento       | ![Visual Studio Code](https://img.shields.io/badge/Visual%20Studio%20Code-0078d7.svg?style=for-the-badge&logo=visual-studio-code&logoColor=white) ![Kaggle](https://img.shields.io/badge/Kaggle-035a7d?style=for-the-badge&logo=kaggle&logoColor=white) Google Colab |

    <br/>
    As se√ß√µes a seguir apresentam as predi√ß√µes realizadas pelo modelo treinado
    para todas as avalia√ß√µes. Nelas, √© poss√≠vel comparar os dados reais com
    as previs√µes geradas pelo Modelo, permitindo uma avalia√ß√£o clara da
    efic√°cia do modelo na tarefa proposta.

    <br/>
    """,
        unsafe_allow_html=True,
    )


def positive_reviews_ranking():
    st.subheader("Ranking de avalia√ß√µes positivas por empresa")

    st.markdown(
        """
    Este gr√°fico ilustra as cinco empresas que apresentam um n√∫mero de
    avalia√ß√µes positivas superior ao de avalia√ß√µes negativas. Para garantir
    a relev√¢ncia dos dados, foram consideradas apenas as empresas que
    possuem pelo menos 21 avalia√ß√µes, um crit√©rio que representa a metade da
    mediana de avalia√ß√µes de todas as empresas analisadas.
"""
    )

    top_positive_companies_df = st.session_state.get("top_positive_companies_df")

    fig, ax = plt.subplots(1, figsize=(10, 8))

    sns.barplot(
        data=top_positive_companies_df,
        x="sentiment_count",
        y="company",
        hue="predicted_sentiment_plot",
        palette=[
            ReportConfig.POSITIVE_SENTIMENT_COLOR,
            ReportConfig.NEGATIVE_SENTIMENT_COLOR,
            ReportConfig.NEUTRAL_SENTIMENT_COLOR,
        ],
        ax=ax,
        width=0.9,
        orient="h",
    )

    # Annotates
    for p in ax.patches:
        ax.annotate(
            text=f"{p.get_width():.0f}",
            xy=(p.get_width(), (p.get_y() + p.get_height() / 2)),
            ha="center",
            va="center",
            fontsize=10,
            color="black",
            xytext=(10, 0),
            textcoords="offset points",
        )

    # Axes config
    ax.set_xlabel("")

    ax.set_xticks([])

    ax.set_ylabel("")

    ax.set_title(
        "Ranking de avalia√ß√µes positivas por empresa",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.1,
    )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)

    positive_patch = plt.Rectangle(
        (0, 0), 1, 1, fc=ReportConfig.POSITIVE_SENTIMENT_COLOR
    )
    negative_patch = plt.Rectangle(
        (0, 0), 1, 1, fc=ReportConfig.NEGATIVE_SENTIMENT_COLOR
    )
    neutral_patch = plt.Rectangle((0, 0), 1, 1, fc=ReportConfig.NEUTRAL_SENTIMENT_COLOR)

    ax.legend(
        # title="Sentimento",
        handles=[positive_patch, negative_patch, neutral_patch],
        labels=ReportConfig.PLOT_SENTIMENT_LABELS,
        bbox_to_anchor=(0.5, 1.1),
        loc="upper center",
        edgecolor="1",
        ncols=3,
    )

    # plt.savefig(
    #     "positive_reviews_by_company.png",
    #     transparent=False,
    #     dpi=300,
    #     bbox_inches="tight",
    # )

    st.pyplot(fig)


def negative_reviews_ranking():
    st.subheader("Ranking de avalia√ß√µes negativas por empresa")

    st.markdown(
        """
    Este gr√°fico mostra as empresas que apresentam um n√∫mero de
    avalia√ß√µes negativas superior ao de avalia√ß√µes positivas, seguindo
    os mesmos crit√©rios do gr√°fico anterior.
"""
    )

    top_negative_companies_df = st.session_state.get("top_negative_companies_df")

    fig, ax = plt.subplots(1, figsize=(10, 8))

    sns.barplot(
        data=top_negative_companies_df,
        x="sentiment_count",
        y="company",
        hue="predicted_sentiment_plot",
        palette=[
            ReportConfig.POSITIVE_SENTIMENT_COLOR,
            ReportConfig.NEGATIVE_SENTIMENT_COLOR,
            ReportConfig.NEUTRAL_SENTIMENT_COLOR,
        ],
        ax=ax,
        width=0.9,
        orient="h",
    )

    # Annotates
    for p in ax.patches:
        ax.annotate(
            text=f"{p.get_width():.0f}",
            xy=(p.get_width(), (p.get_y() + p.get_height() / 2)),
            ha="center",
            va="center",
            fontsize=10,
            color="black",
            xytext=(10, 0),
            textcoords="offset points",
        )

    # Axes config
    ax.set_xlabel("")

    ax.set_xticks([])

    ax.set_ylabel("")

    ax.set_title(
        "Ranking de avalia√ß√µes negativas por empresa",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.1,
    )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)

    positive_patch = plt.Rectangle(
        (0, 0), 1, 1, fc=ReportConfig.POSITIVE_SENTIMENT_COLOR
    )
    negative_patch = plt.Rectangle(
        (0, 0), 1, 1, fc=ReportConfig.NEGATIVE_SENTIMENT_COLOR
    )
    neutral_patch = plt.Rectangle((0, 0), 1, 1, fc=ReportConfig.NEUTRAL_SENTIMENT_COLOR)

    ax.legend(
        # title="Sentimento",
        handles=[positive_patch, negative_patch, neutral_patch],
        labels=ReportConfig.PLOT_SENTIMENT_LABELS,
        bbox_to_anchor=(0.5, 1.1),
        loc="upper center",
        edgecolor="1",
        ncols=3,
    )

    # plt.savefig(
    #     "negative_reviews_by_company.png",
    #     transparent=True,
    #     dpi=300,
    #     bbox_inches="tight",
    # )

    st.pyplot(fig)

    st.markdown(
        """
        O ranking completo de avalia√ß√µes por empresa pode ser visualizado no
        menu <a target="_self" href="./Ranking_geral_de_avalia√ß√µes">ü•áRanking
        geral de avalia√ß√µes</a>.

        <br/>
    """,
        unsafe_allow_html=True,
    )


def company_analisys():
    st.subheader("Sentimentos das Avalia√ß√µes por Empresa")

    st.markdown(
        """
    A visualiza√ß√£o da distribui√ß√£o de avalia√ß√µes e emo√ß√µes em todas as empresas permite uma compara√ß√£o r√°pida e uma vis√£o abrangente do panorama geral.
"""
    )

    reviews_df = st.session_state.get("reviews_df")

    fig, ax = plt.subplots(1, figsize=(12, 6))
    sns.countplot(
        data=reviews_df,
        x="company",
        hue="predicted_sentiment",
        order=reviews_df["company"].value_counts().index,
        ax=ax,
        palette=ReportConfig.SENTIMENT_PALETTE,
    )

    for p in ax.patches:
        ax.annotate(
            f"{int(p.get_height())}",
            (p.get_x() + p.get_width() / 2.0, p.get_height()),
            ha="center",
            va="center",
            fontsize=6,
            color="black",
            xytext=(0, 5),
            textcoords="offset points",
        )

    sns.despine(bottom=False, left=True)

    plt.title(
        "Sentimentos das Avalia√ß√µes por Empresa",
        fontdict={
            "weight": "bold",
            "size": ReportConfig.CHART_TITLE_FONT_SIZE,
        },
    )

    plt.xlabel("")
    plt.ylabel("")

    plt.xticks(rotation=45, ha="right")
    plt.yticks([])

    plt.legend(title="Sentimento", labels=ReportConfig.SENTIMENT_DICT.values())

    st.pyplot(fig)


def sentiment_reviews_along_time():
    st.subheader("Sentimento das avalia√ß√µes ao longo do tempo")

    st.markdown(
        """
     Este gr√°fico revela que as avalia√ß√µes positivas sempre foram mais
     frequentes do que as negativas e neutras. O ano de 2022 destacou-se como
     o per√≠odo com o maior n√∫mero total de avalia√ß√µes, apresentando tamb√©m a
     maior disparidade entre as avalia√ß√µes positivas e negativas.

    <br/>
""",
        unsafe_allow_html=True,
    )

    reviews_df = st.session_state.get("reviews_df")

    reviews_df["review_date"] = pd.to_datetime(
        reviews_df["review_date"], format="%Y-%m-%d"
    )
    reviews_df["year"] = reviews_df["review_date"].dt.year

    sentiment_counts = (
        reviews_df.groupby(["year", "predicted_sentiment"])
        .size()
        .reset_index(name="count")
    )

    fig, ax = plt.subplots(1, figsize=(12, 6))
    sns.lineplot(
        data=sentiment_counts,
        x="year",
        y="count",
        hue="predicted_sentiment",
        palette=ReportConfig.SENTIMENT_PALETTE,
        ax=ax,
    )

    # Annotations for number of reviews per sentiment
    years_unique = sentiment_counts["year"].unique()
    for year in years_unique:
        year_counts = sentiment_counts[sentiment_counts["year"] == year][
            "count"
        ].tolist()

        neutral_counts, positive_counts, negative_counts = (year_counts + [None] * 3)[
            :3
        ]

        if neutral_counts:
            ax.text(
                x=year,
                y=neutral_counts - 8,
                s=f"{neutral_counts}",
                ha="center",
                color=ReportConfig.NEUTRAL_SENTIMENT_COLOR,
            )

        if positive_counts:
            ax.text(
                x=year,
                y=positive_counts + 8,
                s=f"{positive_counts}",
                ha="center",
                color=ReportConfig.POSITIVE_SENTIMENT_COLOR,
            )

        if negative_counts:
            ax.text(
                x=year,
                y=negative_counts - 8,
                s=f"{negative_counts}",
                ha="center",
                color=ReportConfig.NEGATIVE_SENTIMENT_COLOR,
            )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    # ax.spines["bottom"].set_visible(False)

    ax.set_xlabel("Ano")
    ax.set_ylabel("Quantidade de avalia√ß√µes")

    ax.set_title(
        "Sentimento das avalia√ß√µes ao longo do tempo",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.1,
    )

    handles, labels = ax.get_legend_handles_labels()
    order_map = {label: handle for handle, label in zip(handles, labels)}
    handles = [order_map[sentiment] for sentiment in ReportConfig.PLOT_SENTIMENT_VALUES]

    plt.legend(
        # title="Sentimento",
        handles=handles,
        labels=ReportConfig.PLOT_SENTIMENT_LABELS,
        bbox_to_anchor=(0.5, 1.1),
        loc="upper center",
        edgecolor="1",
        ncols=3,
    )

    st.pyplot(fig)

    st.markdown(
        """
        As avalia√ß√µes ao longo do tempo por empresa podem ser visualizadas no
        menu <a target="_self" href="./Avalia√ß√µes_ao_longo_do_tempo">
        üìâAvalia√ß√µes ao longo do tempo</a>.

        <br/>
    """,
        unsafe_allow_html=True,
    )

    # plt.savefig(
    #     "sentiments_reviews_along_time.png",
    #     transparent=True,
    #     dpi=300,
    #     bbox_inches="tight",
    # )


def rating_star_analysis():
    warnings.filterwarnings("ignore", "use_inf_as_na")
    reviews_df = st.session_state.get("reviews_df")

    st.subheader(
        "Distribui√ß√£o de Sentimentos por Quantidade de Estrelas em Avalia√ß√µes, por Empresa"
    )

    st.markdown(
        """
    Esta an√°lise mostra padr√µes interessantes na rela√ß√£o entre as avalia√ß√µes e o n√∫mero de estrelas atribu√≠das, revelando correla√ß√µes intrigantes entre a satisfa√ß√£o dos funcion√°rios e a classifica√ß√£o geral.
"""
    )

    g = sns.FacetGrid(
        reviews_df,
        col="company",
        hue="predicted_sentiment",
        col_wrap=4,
    )
    g.map(sns.histplot, "star_rating")

    g.set_titles("{col_name}")
    g.set_axis_labels("Star Rating", "Count")
    g.add_legend(
        title="Predicted Sentiment",
        labels=list(ReportConfig.SENTIMENT_DICT.values()),
    )

    st.pyplot(g)


def rating_star_analysis2():
    reviews_df = st.session_state.get("reviews_df")

    st.subheader(
        "Distribui√ß√£o de Sentimentos por Quantidade de Estrelas em Avalia√ß√µes, por Empresa"
    )

    st.markdown(
        """
        Esta an√°lise mostra padr√µes interessantes na rela√ß√£o entre as avalia√ß√µes e o n√∫mero de estrelas atribu√≠das, revelando correla√ß√µes intrigantes entre a satisfa√ß√£o dos funcion√°rios e a classifica√ß√£o geral.
    """
    )

    company = st.selectbox(
        label="Empresa",
        options=reviews_df["company"].unique().tolist(),
        key="rating_star_company_input",
    )

    filtered_df = reviews_df[reviews_df["company"] == company][
        [
            "company",
            "employee_role",
            "employee_detail",
            "review_text",
            "review_date",
            "star_rating",
            "predicted_sentiment",
            "sentiment_label",
        ]
    ]
    filtered_df.reset_index(drop=True, inplace=True)

    sentiment_counts = (
        filtered_df.groupby(["company", "star_rating", "predicted_sentiment"])
        .size()
        .reset_index(name="count")
    )

    fig, ax = plt.subplots(1, figsize=(12, 8))

    sns.scatterplot(
        data=sentiment_counts,
        x="star_rating",
        y="count",
        hue="predicted_sentiment",
        # style="company",
        ax=ax,
        palette=sns.color_palette(),
    )

    plt.title(
        "Sentiment Counts by Star Rating and Company",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
    )
    plt.xlabel("Star Rating")
    plt.ylabel("Count")

    plt.xticks(ticks=sorted(reviews_df["star_rating"].unique()))

    handles, labels = ax.get_legend_handles_labels()
    handles[0].set_color([ReportConfig.NEGATIVE_SENTIMENT_COLOR])
    handles[1].set_color([ReportConfig.POSITIVE_SENTIMENT_COLOR])
    handles[2].set_color([ReportConfig.NEUTRAL_SENTIMENT_COLOR])

    legend_labels = [
        ReportConfig.SENTIMENT_DICT[i] for i in range(len(ReportConfig.SENTIMENT_DICT))
    ]

    plt.legend(
        title="Sentiment",
        labels=legend_labels,
        bbox_to_anchor=(1.05, 1),
        loc="upper left",
    )

    st.pyplot(fig)

    st.write("Avalia√ß√µes filtradas")
    filtered_df = filtered_df.drop(labels="predicted_sentiment", axis=1)
    st.dataframe(filtered_df)


def rating_star_analysis3():
    reviews_df = st.session_state.get("reviews_df")
    reviews_df = create_predicted_sentiment_plot(reviews_df)

    st.subheader("Distribui√ß√£o de sentimentos por quantidade de estrelas")

    st.markdown(
        """
        Este gr√°fico ilustra que:
        - As avalia√ß√µes de 1 a 3 estrelas apresentam um sentimento
        predominantemente negativo.
        - Por outro lado, as avalia√ß√µes de 4 estrelas mostram uma distribui√ß√£o
        equilibrada entre sentimentos positivos e negativos.
        - J√° as avalia√ß√µes de 5 estrelas s√£o majoritariamente positivas,
        destacando-se tamb√©m um n√∫mero significativo de avalia√ß√µes neutras.

        Essa predomin√¢ncia de avalia√ß√µes neutras em avalia√ß√µes de 5 estrelas
        pode ser atribu√≠da √† exig√™ncia no Glassdoor de preencher as se√ß√µes
        *Pr√≥s* e *Contras*. Em diversas avalia√ß√µes, os usu√°rios n√£o encontram
        aspectos negativos a serem mencionados na se√ß√£o *Contras*, resultando
        em coment√°rios neutros como `N√£o h√° nada a ser apontado` ou `N√£o tenho
        nada a reclamar`.
    """
    )

    filtered_df = reviews_df[
        [
            "company",
            "employee_role",
            "employee_detail",
            "review_text",
            "review_date",
            "star_rating",
            "predicted_sentiment_plot",
            "sentiment_label",
        ]
    ]

    filtered_df.reset_index(drop=True, inplace=True)

    if len(filtered_df) > 0:
        sentiment_counts = (
            filtered_df.groupby(["star_rating", "predicted_sentiment_plot"])
            .size()
            .reset_index(name="count")
        )

        fig, ax = plt.subplots(1, figsize=(10, 6))

        bars = sns.barplot(
            data=sentiment_counts,
            x="star_rating",
            y="count",
            hue="predicted_sentiment_plot",
            ax=ax,
            palette=[
                ReportConfig.POSITIVE_SENTIMENT_COLOR,
                ReportConfig.NEGATIVE_SENTIMENT_COLOR,
                ReportConfig.NEUTRAL_SENTIMENT_COLOR,
            ],
        )

        for p in bars.patches:
            height = p.get_height()
            if math.isnan(height):
                height = 0.0

            bars.annotate(
                text=f"{int(height)}",
                xy=(p.get_x() + p.get_width() / 2.0, height),
                ha="center",
                va="center",
                fontsize=10,
                color="black",
                xytext=(0, 5),
                textcoords="offset points",
            )

        ax.set_title(
            "Distribui√ß√£o de sentimentos por quantidade de estrelas",
            fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
            y=1.1,
        )

        ax.set_xlabel("")
        ax.set_xticklabels(
            ["\u2605" * int(x) for x in sentiment_counts["star_rating"].unique()]
        )

        ax.set_yticks([])
        ax.set_ylabel("")

        ax.spines["top"].set_visible(False)
        ax.spines["right"].set_visible(False)
        ax.spines["left"].set_visible(False)

        positive_patch = plt.Rectangle(
            (0, 0), 1, 1, fc=ReportConfig.POSITIVE_SENTIMENT_COLOR
        )
        negative_patch = plt.Rectangle(
            (0, 0), 1, 1, fc=ReportConfig.NEGATIVE_SENTIMENT_COLOR
        )
        neutral_patch = plt.Rectangle(
            (0, 0), 1, 1, fc=ReportConfig.NEUTRAL_SENTIMENT_COLOR
        )

        ax.legend(
            # title="Sentimento",
            handles=[positive_patch, negative_patch, neutral_patch],
            labels=ReportConfig.PLOT_SENTIMENT_LABELS,
            bbox_to_anchor=(0.5, 1.1),
            loc="upper center",
            edgecolor="1",
            ncols=3,
        )

        st.pyplot(fig)

        # plt.savefig(
        #     "sentiment_by_rating_star.png",
        #     transparent=True,
        #     dpi=300,
        #     bbox_inches="tight",
        # )
    else:
        st.error(
            AppMessages.ERROR_EMPTY_DATAFRAME,
            icon="üö®",
        )

    st.markdown(
        """
        A distribui√ß√£o de sentimentos por quantidades de estrelas para cada
        empresa pode ser visualizada no menu
        <a target="_self" href="./Avalia√ß√µes_por_quantidade_de_estrelas">
        üìäAvalia√ß√µes por quantidade de estrelas</a>.

        <br/>
    """,
        unsafe_allow_html=True,
    )


def wordcloud_analysis():
    st.subheader("Word Cloud de todas as avalia√ß√µes")

    st.markdown(
        """
    A Word Cloud (Nuvem de Palavras) √© uma representa√ß√£o visual que ilustra as
    palavras mais frequentemente utilizadas no conjunto de avalia√ß√µes. Neste
    gr√°fico, as palavras aparecem em tamanhos variados, refletindo sua
    frequ√™ncia de uso: quanto maior a palavra, mais vezes ela foi mencionada
    nas avalia√ß√µes.

    √â importante ressaltar que as stopwords, que s√£o palavras comuns e
    geralmente sem significado relevante para a an√°lise (como "e", "a", "o",
    "de"), foram exclu√≠das desta visualiza√ß√£o.

    Essa abordagem permite uma an√°lise mais clara e focada, facilitando a
    identifica√ß√£o r√°pida dos t√≥picos mais relevantes e das percep√ß√µes
    predominantes dos usu√°rios.
"""
    )

    reviews_df = st.session_state.get("reviews_df")
    review_text = reviews_df["review_text"].str.split().values.tolist()
    corpus = [word for i in review_text for word in i]

    non_stopwords_corpus = []
    for word in corpus:
        word_lower = word.lower()
        cleaned_word = word_lower.translate(TRANSLATION_TABLE_SPECIAL_CHARACTERS)
        if cleaned_word and cleaned_word not in STOPWORDS:
            non_stopwords_corpus.append(cleaned_word)

    counter = Counter(non_stopwords_corpus)
    most_common_words = counter.most_common(n=50)

    wordcloud = WordCloud(
        background_color="white",
        random_state=ReportConfig.RANDOM_SEED,
        # max_words=50,
        width=1024,
        height=768,
    )

    fig, ax = plt.subplots(1, figsize=(10, 6))
    plt.axis("off")

    ax.imshow(wordcloud.generate_from_frequencies(dict(most_common_words)))

    st.pyplot(fig)

    st.markdown(
        """
        A Word Cloud de avalia√ß√µes por sentimento e por empresa pode ser
        visualizada no menu
        <a target="_self" href="./Word_Cloud">‚òÅÔ∏èWord Cloud</a>.
    """,
        unsafe_allow_html=True,
    )


def most_common_words_analysis():
    st.subheader("Top 10 palavras mais frequentes nas avalia√ß√µes")

    st.markdown(
        """
        Embora a Word Cloud ofere√ßa uma vis√£o geral interessante das
        palavras mais utilizadas nas avalia√ß√µes, ela pode n√£o ser a melhor
        op√ß√£o para destacar de forma clara e precisa a palavra mais frequente.
        Para complementar essa an√°lise, √© mostrado o gr√°fico de barras que
        apresenta as 10 palavras mais frequentemente utilizadas nas avalia√ß√µes
        analisadas.

        Este gr√°fico segue os mesmos crit√©rios da Word Cloud, garantindo que
        as palavras selecionadas sejam relevantes e significativas. Com a
        disposi√ß√£o em barras, √© poss√≠vel visualizar facilmente a frequ√™ncia de
        cada palavra, permitindo uma compara√ß√£o direta entre elas.

        Essa abordagem torna a interpreta√ß√£o dos dados mais intuitiva e
        acess√≠vel, facilitando a identifica√ß√£o dos temas mais recorrentes nas
        avalia√ß√µes.
"""
    )

    reviews_df = st.session_state.get("reviews_df")
    review_text = reviews_df["review_text"].str.split().values.tolist()
    corpus = [word for i in review_text for word in i]

    non_stopwords_corpus = []
    for word in corpus:
        word_lower = word.lower()
        cleaned_word = word_lower.translate(TRANSLATION_TABLE_SPECIAL_CHARACTERS)
        if cleaned_word and cleaned_word not in STOPWORDS:
            non_stopwords_corpus.append(cleaned_word)

    counter = Counter(non_stopwords_corpus)
    most_common_words = counter.most_common(n=10)

    words, counts = zip(*most_common_words)  # Unzip the words and counts
    most_common_words_df = pd.DataFrame({"words": words, "counts": counts})

    fig, ax = plt.subplots(1, figsize=(10, 8))

    sns.barplot(
        data=most_common_words_df,
        x="counts",
        y="words",
        ax=ax,
        width=0.9,
        orient="h",
    )

    # Annotates
    for p in ax.patches:
        ax.annotate(
            text=f"{p.get_width():.0f}",
            xy=(p.get_width(), (p.get_y() + p.get_height() / 2)),
            ha="center",
            va="center",
            fontsize=10,
            color="white",
            xytext=(-15, 0),
            textcoords="offset points",
        )

    # Axes config
    ax.set_xlabel("")

    ax.set_xticks([])

    ax.set_ylabel("")

    ax.set_title(
        "Top 10 palavras mais frequentes nas avalia√ß√µes",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.0,
    )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)

    st.pyplot(fig)

    st.markdown(
        """
        As Top 10 palavras mais frequentes nas avalia√ß√µes por empresa e por
        sentimento podem ser visualizadas no menu <a target="_self" href="./Top_10_palavras_mais_usadas">üìäTop 10 palavras mais frequentes</a>.

        <br/>
    """,
        unsafe_allow_html=True,
    )


def ngram_analysis():
    st.subheader("Top 10 NGrams mais frequentes nas avalia√ß√µes")

    st.markdown(
        """
    Embora o gr√°fico de palavras mais frequentes forne√ßa uma vis√£o inicial
    sobre os termos mais utilizados nas avalia√ß√µes, ele n√£o captura a riqueza
    dos contextos em que essas palavras aparecem. Palavras isoladas podem ter
    significados variados e n√£o revelam como elas se combinam para formar
    ideias ou sentimentos mais complexos. Por exemplo, a palavra `crescimento`
    pode aparecer frequentemente, mas sem o contexto, como em `oportunidade de
    crescimento`, seu significado pode ser amb√≠guo.

    Os N-Gramas s√£o sequ√™ncias cont√≠guas de "n" itens (palavras ou
    caracteres) e s√£o essenciais para uma an√°lise mais profunda, pois permitem
    identificar padr√µes e temas recorrentes nas avalia√ß√µes.

    Ao considerar as combina√ß√µes de palavras, √© poss√≠vel entender melhor as
    percep√ß√µes dos funcion√°rios e os aspectos mais relevantes de suas
    experi√™ncias. Essa an√°lise revelou que as combina√ß√µes de palavras mais
    frequentes, considerando todas as avalia√ß√µes, foram: `ambiente de
    trabalho`, `plano de carreira`, `plano de sa√∫de` e `oportunidade de
    crescimento`.
"""
    )

    reviews_df = st.session_state.get("reviews_df")

    review_text = reviews_df["review_text"]

    vec = CountVectorizer(ngram_range=(3, 3)).fit(review_text)
    bag_of_words = vec.transform(review_text)
    sum_words = bag_of_words.sum(axis=0)

    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]
    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)

    top_n_grams = words_freq[:10]
    x, y = map(list, zip(*top_n_grams))

    fig, ax = plt.subplots(1, figsize=(10, 8))

    sns.barplot(
        x=y,
        y=x,
        ax=ax,
        width=0.9,
        orient="h",
    )

    # Annotates
    for p in ax.patches:
        ax.annotate(
            text=f"{p.get_width():.0f}",
            xy=(p.get_width(), (p.get_y() + p.get_height() / 2)),
            ha="center",
            va="center",
            fontsize=11,
            color="white",
            xytext=(-15, 0),
            textcoords="offset points",
        )

    # Axes config
    ax.set_xlabel("")

    ax.set_xticks([])

    ax.set_ylabel("")

    ax.set_title(
        "Top 10 NGrams mais frequentes nas avalia√ß√µes",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.0,
    )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)

    st.pyplot(fig)

    st.markdown(
        """
        Os Top 10 NGrams mais frequentes nas avalia√ß√µes de cada empresa pode
        ser visualizado no menu <a target="_self" href="./NGrams">üî†NGrams</a>.

        <br/>
    """,
        unsafe_allow_html=True,
    )


def conclusion():
    # TODO: fix the final description
    st.subheader("Conclus√£o")

    st.markdown(
        """
    **A an√°lise de sentimentos das avalia√ß√µes no Glassdoor de 22 empresas de
    Tecnologia em Cuiab√°** revelou que o modelo de IA, baseado na t√©cnica de
    Transfer Learning com BERTimbau, **demonstrou uma alta acur√°cia de 95% na
    classifica√ß√£o das avalia√ß√µes**, evidenciando a efic√°cia metodologia aplicada.

    Os resultados indicam que **15 das 22 empresas analisadas possuem mais
    avalia√ß√µes positivas do que negativas**, refletindo um ambiente de trabalho
    predominantemente favor√°vel.

    As **avalia√ß√µes positivas** frequentemente mencionam temas como **ambiente
    de trabalho**, **plano de sa√∫de** e **oportunidade de crescimento**,
    enquanto as **avalia√ß√µes negativas** destacam preocupa√ß√µes com **plano de
    carreira**, **sal√°rio abaixo do mercado** e, em alguns casos, o **plano de
    sa√∫de**. As **avalia√ß√µes neutras**, embora menos frequentes, sugerem que
    muitos colaboradores **n√£o encontraram aspectos negativos a serem
    destacados**, indicando uma satisfa√ß√£o geral com suas experi√™ncias.

    Al√©m disso, a an√°lise temporal revelou que **as avalia√ß√µes positivas sempre
    foram predominantes em rela√ß√£o as demais**. Esta an√°lise tamb√©m mostrou que
    houve um grande aumento no n√∫mero de avalia√ß√µes entre 2020 e 2022, per√≠odo
    da Pandemia de Covid-19, onde as empresas contrataram mais.

    Esses insights s√£o fundamentais para as empresas, pois proporcionam uma
    vis√£o clara das √°reas que precisam de melhorias e das que j√° est√£o
    apresentando resultados positivos. Com base nessas informa√ß√µes, as
    organiza√ß√µes podem desenvolver estrat√©gias eficazes para aprimorar o
    ambiente de trabalho, focar em benef√≠cios que realmente importam para os
    colaboradores e, assim, n√£o apenas aumentar a reten√ß√£o de talentos, mas
    tamb√©m atrair profissionais que buscam ambientes com melhores avalia√ß√µes.
    A reputa√ß√£o positiva, refletida nas avalia√ß√µes, pode ser um diferencial
    decisivo na escolha de uma empresa por candidatos qualificados, impactando
    diretamente o sucesso e a competitividade no mercado.
"""
    )


if __name__ == "__main__":
    warnings.filterwarnings("ignore", "use_inf_as_na")

    st.set_page_config(
        page_title="Home",
        page_icon=":house:",
    )

    st.markdown(
        ReportConfig.CUSTOM_CSS,
        unsafe_allow_html=True,
    )

    st.sidebar.warning(AppMessages.WARNING_PLOT_NOT_WORKING)

    st.header(
        "An√°lise de sentimentos nas avalia√ß√µes do Glassdoor: Um estudo sobre empresas de Tecnologia em Cuiab√°"
    )

    if "reviews_df" not in st.session_state:
        # Reviews DF
        reviews_df = pd.read_csv("./glassdoor_reviews_predicted.csv")

        # TODO:check where the "sentiment" column is used and if it is being
        # used instead of "predicted_sentiment"

        st.session_state["reviews_df"] = reviews_df

        # Top Companies Reviews DF
        if "top_positive_companies_df" not in st.session_state:
            top_positive_companies_df, top_negative_companies_df = (
                get_ranking_positive_negative_companies(reviews_df)
            )

            st.session_state["top_positive_companies_df"] = top_positive_companies_df
            st.session_state["top_negative_companies_df"] = top_negative_companies_df

    introduction()

    # company_analisys()

    # TODO: create positive reviews ranking for `sentiment` column.
    positive_reviews_ranking()
    # TODO: create negative reviews ranking for `sentiment` column.
    negative_reviews_ranking()

    # TODO: create sentiment reviews along time for `sentiment` column.
    sentiment_reviews_along_time()

    # rating_star_analysis()
    # rating_star_analysis2()

    # TODO: create rating star analysis for `sentiment` column.
    rating_star_analysis3()

    # TODO: create wordcloud for `sentiment` column.
    wordcloud_analysis()

    # TODO: create most common words plot for `sentiment` column.
    most_common_words_analysis()

    # TODO: create ngram plot for `sentiment` column.
    ngram_analysis()

    # TODO: refact conclusion, explaining that the model is efficient for sentiment classification
    conclusion()
