import math
import warnings
from collections import Counter

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import streamlit as st
from sklearn.feature_extraction.text import CountVectorizer
from wordcloud import WordCloud

from app_messages import AppMessages
from report_config import ReportConfig
from utils import (
    STOPWORDS,
    TRANSLATION_TABLE_SPECIAL_CHARACTERS,
    create_predicted_sentiment_plot,
    get_ranking_positive_negative_companies,
)


def introduction():
    st.markdown(
        """
       As avalia√ß√µes dos funcion√°rios no Glassdoor s√£o como janelas para o
       cora√ß√£o de uma empresa. Elas revelam n√£o apenas a cultura e o ambiente
       de trabalho, mas tamb√©m o pulso emocional dos colaboradores. Em setores
       altamente competitivos, como o de Tecnologia, entender essas emo√ß√µes
       pode ser a chave para atrair talentos, encantar clientes e impulsionar
       o sucesso empresarial.

       A fim de identificar as emo√ß√µes nas avalia√ß√µes no Glassdoor de 22
       empresas de Tecnologia de Cuiab√°, foi criado um Modelo de IA utilizando
       a t√©cnica de Transfer Learning com BERT (Bidirectional Encoder
       Representations from Transformers), um Modelo de linguagem pr√©-treinado
       que utiliza a representa√ß√£o bidirecional de texto para entender o
       contexto das palavras em uma frase ou texto.

       O Modelo pr√©-treinado utilizado como base para a cria√ß√£o do Modelo de
       identifica√ß√£o de sentimentos foi o BERTimbau, um Modelo que consiste no
       BERT, mas treinado com a l√≠ngua portuguesa. Os insights que surgiram da
       an√°lise das avalia√ß√µes no Glassdoor s√£o apresentados a seguir.
"""
    )


def general_analysis():
    st.subheader("Distribui√ß√£o de sentimentos das avalia√ß√µes")

    st.markdown(
        """
       **Metodologia**

        Antes de treinar o modelo de aprendizado de m√°quina para classificar
        os sentimentos das avalia√ß√µes extra√≠das no Glassdoor, foi necess√°rio
        preparar os dados. Essa prepara√ß√£o envolveu:

        *Classifica√ß√£o manual das avalia√ß√µes*

        Uma parte das avalia√ß√µes foi classificada manualmente, utilizando uma
        ferramenta de anota√ß√£o criada pelo pr√≥prio autor. Esse conjunto de
        dados extra√≠dos e classificados manualmente √© chamado de "sentimentos
        anotados" e serviu como base de treinamento e valida√ß√£o para o modelo.

        *Tratamento do desequil√≠brio de classes*

        Ao analisar o conjunto de dados anotados, observou-se um desequil√≠brio
        significativo entre as classes de sentimento. Avalia√ß√µes classificadas
        como Neutro representavam quase 5 vezes menos do que as demais classes
        (Positivo e Negativo). Para lidar com esse problema, foi aplicada a
        t√©cnica de oversampling na classe Neutro, replicando aleatoriamente
        algumas amostras dessa classe durante o treinamento. Isso ajudou a
        balancear a distribui√ß√£o das classes e melhorar o desempenho do modelo
        na identifica√ß√£o correta de avalia√ß√µes Neutras.

        **Resultados**

        *Arquitetura do Modelo*

        Para identificar a melhor configura√ß√£o na classifica√ß√£o das tr√™s
        classes de sentimento (Neutro, Positivo e Negativo), diversas
        abordagens foram testadas. As configura√ß√µes incluem:
        - Modelo sem congelamento das camadas do BERTimbau.
        - Modelo com congelamento das camadas do BERTimbau.
        - Oversampling sem congelamento do BERTimbau.
        - Oversampling com congelamento do BERTimbau.

        Dentre todas as configura√ß√µes testadas, a combina√ß√£o que apresentou a
        melhor acur√°cia foi a do modelo com Oversampling e congelamento das
        camadas do BERTimbau.

        A arquitetura do modelo consiste em:
        - Camada de Entrada: Conectada ao BERTimbau com suas camadas
        congeladas.
        - Camadas Ocultas:
            - Primeira camada oculta com 300 neur√¥nios.
            - Segunda camada oculta com 100 neur√¥nios.
            - Terceira camada oculta com 50 neur√¥nios.

        A √∫ltima camada oculta √© conectada a uma fun√ß√£o Softmax, que
        classifica a entrada em uma das tr√™s classes de sentimento: Neutro,
        Positivo ou Negativo.

        ![Arquitetura do modelo](https://github.com/stevillis/glassdoor-reviews-report/blob/master/img/arquitetura_do_modelo.png?raw=true "Arquitetuar do Modelo")

        *Treinamento do Modelo*

        O modelo foi treinado utilizando 80% dos dados dispon√≠veis, enquanto
        os 20% restantes foram reservados para testes. A tabela a seguir
        apresenta as m√©tricas de desempenho do modelo treinado. As linhas 0,
        1 e 2 representam, respectivamente, as classes: Neutro, Positivo e
        Negativo.

        |              | precision | recall | f1-score | support |
        | ------------ | --------- | ------ | -------- | ------- |
        | 0            | 0.96      | 0.98   | 0.97     | 197     |
        | 1            | 0.92      | 0.98   | 0.95     | 256     |
        | 2            | 0.98      | 0.88   | 0.93     | 199     |
        | accuracy     |           |        | 0.95     | 652     |
        | macro avg    | 0.96      | 0.95   | 0.95     | 652     |
        | weighted avg | 0.95      | 0.95   | 0.95     | 652     |

        $~$

        *Compara√ß√£o entre dados anotados e classificados pelo modelo*

        As barras do gr√°fico s√£o divididas em duas categorias: uma
        representando os dados anotados manualmente e a outra representando as
        previs√µes do modelo.
        - Classifica√ß√£o Positiva: O modelo identificou 1257 avalia√ß√µes como
        positivas, o que √© apenas 12 a menos do que a anota√ß√£o manual. Isso
        indica uma alta precis√£o na detec√ß√£o de sentimentos positivos.
        - Classifica√ß√£o Negativa: O modelo classificou 1052 avalia√ß√µes como
        negativas, superando a anota√ß√£o manual em 31 casos. Essa leve
        discrep√¢ncia sugere que o modelo pode estar identificando um n√∫mero
        maior de sentimentos negativos do que realmente existe nos dados
        anotados.
        - Classifica√ß√£o Neutra: O modelo identificou 223 avalia√ß√µes como
        neutras, o que representa uma diferen√ßa de 19 casos a menos em
        compara√ß√£o com as anota√ß√µes manuais. Essa discrep√¢ncia evidencia a
        conhecida dificuldade do modelo em reconhecer sentimentos neutros,
        atribu√≠da ao desbalanceamento em rela√ß√£o √†s classes positivas e
        negativas.

            Entretanto, a aplica√ß√£o da t√©cnica de Oversampling demonstrou ser
            eficaz, uma vez que, sem essa abordagem, o modelo apresentava
            dificuldades significativas em identificar as classes neutras durante
            o treinamento.
"""
    )

    reviews_df = st.session_state.get("reviews_df")

    fig, ax = plt.subplots(2, 1, figsize=(8, 4))

    # Annotated sentiment
    sentiment_counts = reviews_df["sentiment"].value_counts().reset_index()
    sentiment_counts.columns = ["sentiment", "count"]

    sentiment_counts["sentiment"] = sentiment_counts["sentiment"].map(
        lambda x: ReportConfig.SENTIMENT_DICT[x]
    )

    sns.barplot(
        data=sentiment_counts,
        y="sentiment",
        x="count",
        palette=[
            ReportConfig.POSITIVE_SENTIMENT_COLOR,
            ReportConfig.NEGATIVE_SENTIMENT_COLOR,
            ReportConfig.NEUTRAL_SENTIMENT_COLOR,
        ],
        ax=ax[0],
    )

    ax[0].spines["top"].set_visible(False)
    ax[0].spines["right"].set_visible(False)
    ax[0].spines["bottom"].set_visible(False)

    for p in ax[0].patches:
        ax[0].annotate(
            f"{int(p.get_width())}",
            (p.get_width(), p.get_y() + p.get_height() / 2.0),
            ha="center",
            va="center",
            fontsize=11,
            color="white",
            xytext=(-15, 0),
            textcoords="offset points",
        )

    ax[0].set_xticks([])
    ax[0].set_xlabel("")
    ax[0].set_ylabel("")
    ax[0].set_title(
        "Distribui√ß√£o de sentimentos anotados",
        loc="center",
        fontsize=14,
    )

    # Predicted sentiment
    predicted_sentiment_counts = (
        reviews_df["predicted_sentiment"].value_counts().reset_index()
    )
    predicted_sentiment_counts.columns = ["predicted_sentiment", "count"]

    predicted_sentiment_counts["predicted_sentiment"] = predicted_sentiment_counts[
        "predicted_sentiment"
    ].map(lambda x: ReportConfig.SENTIMENT_DICT[x])

    sns.barplot(
        data=predicted_sentiment_counts,
        y="predicted_sentiment",
        x="count",
        palette=[
            ReportConfig.POSITIVE_SENTIMENT_COLOR,
            ReportConfig.NEGATIVE_SENTIMENT_COLOR,
            ReportConfig.NEUTRAL_SENTIMENT_COLOR,
        ],
        ax=ax[1],
    )

    for p in ax[1].patches:
        ax[1].annotate(
            f"{int(p.get_width())}",
            (p.get_width() - 50, p.get_y() + p.get_height() / 2.0),
            ha="center",
            va="center",
            fontsize=11,
            color="white",
            xytext=(0, 0),
            textcoords="offset points",
        )

    ax[1].set_xticks([])
    ax[1].set_xlabel("")
    ax[1].set_ylabel("")
    ax[1].set_title(
        "Distribui√ß√£o de sentimentos classificados pelo modelo",
        loc="center",
        fontsize=14,
    )

    ax[1].spines["top"].set_visible(False)
    ax[1].spines["right"].set_visible(False)
    ax[1].spines["bottom"].set_visible(False)

    plt.tight_layout()
    st.pyplot(fig)


def positive_reviews_ranking():
    st.subheader("Ranking de avalia√ß√µes positivas por empresa")

    st.markdown(
        """
    Este gr√°fico ilustra as cinco empresas que se apresentam um n√∫mero de
    avalia√ß√µes positivas superior ao de avalia√ß√µes negativas. Para garantir
    a relev√¢ncia dos dados, foram consideradas apenas as empresas que
    possuem pelo menos 21 avalia√ß√µes, um crit√©rio que representa a metade da
    mediana de avalia√ß√µes de todas as empresas analisadas.
"""
    )

    top_positive_companies_df = st.session_state.get("top_positive_companies_df")

    fig, ax = plt.subplots(1, figsize=(10, 8))

    sns.barplot(
        data=top_positive_companies_df,
        x="sentiment_count",
        y="company",
        hue="predicted_sentiment_plot",
        palette=[
            ReportConfig.POSITIVE_SENTIMENT_COLOR,
            ReportConfig.NEGATIVE_SENTIMENT_COLOR,
            ReportConfig.NEUTRAL_SENTIMENT_COLOR,
        ],
        ax=ax,
        width=0.9,
        orient="h",
    )

    # Annotates
    for p in ax.patches:
        ax.annotate(
            text=f"{p.get_width():.0f}",
            xy=(p.get_width(), (p.get_y() + p.get_height() / 2)),
            ha="center",
            va="center",
            fontsize=9,
            color="black",
            xytext=(10, 0),
            textcoords="offset points",
        )

    # Axes config
    ax.set_xlabel("")

    ax.set_xticks([])

    ax.set_ylabel("")

    ax.set_title(
        "Ranking de avalia√ß√µes positivas por empresa",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.1,
    )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)

    positive_patch = plt.Rectangle(
        (0, 0), 1, 1, fc=ReportConfig.POSITIVE_SENTIMENT_COLOR
    )
    negative_patch = plt.Rectangle(
        (0, 0), 1, 1, fc=ReportConfig.NEGATIVE_SENTIMENT_COLOR
    )
    neutral_patch = plt.Rectangle((0, 0), 1, 1, fc=ReportConfig.NEUTRAL_SENTIMENT_COLOR)

    ax.legend(
        # title="Sentimento",
        handles=[positive_patch, negative_patch, neutral_patch],
        labels=["Positivo", "Negativo", "Neutro"],
        bbox_to_anchor=(0.5, 1.1),
        loc="upper center",
        edgecolor="1",
        ncols=3,
    )

    st.pyplot(fig)


def negative_reviews_ranking():
    st.subheader("Ranking de avalia√ß√µes negativas por empresa")

    st.markdown(
        """
    Este gr√°fico ilustra as tr√™s empresas que se apresentam um n√∫mero de
    avalia√ß√µes negativas superior ao de avalia√ß√µes positivas, seguindo
    os mesmos crit√©rios do gr√°fico anterior.
"""
    )

    top_negative_companies_df = st.session_state.get("top_negative_companies_df")

    fig, ax = plt.subplots(1, figsize=(10, 8))

    sns.barplot(
        data=top_negative_companies_df,
        x="sentiment_count",
        y="company",
        hue="predicted_sentiment_plot",
        palette=[
            ReportConfig.POSITIVE_SENTIMENT_COLOR,
            ReportConfig.NEGATIVE_SENTIMENT_COLOR,
            ReportConfig.NEUTRAL_SENTIMENT_COLOR,
        ],
        ax=ax,
        width=0.9,
        orient="h",
    )

    # Annotates
    for p in ax.patches:
        ax.annotate(
            text=f"{p.get_width():.0f}",
            xy=(p.get_width(), (p.get_y() + p.get_height() / 2)),
            ha="center",
            va="center",
            fontsize=9,
            color="black",
            xytext=(10, 0),
            textcoords="offset points",
        )

    # Axes config
    ax.set_xlabel("")

    ax.set_xticks([])

    ax.set_ylabel("")

    ax.set_title(
        "Ranking de avalia√ß√µes negativas por empresa",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.1,
    )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)

    positive_patch = plt.Rectangle(
        (0, 0), 1, 1, fc=ReportConfig.POSITIVE_SENTIMENT_COLOR
    )
    negative_patch = plt.Rectangle(
        (0, 0), 1, 1, fc=ReportConfig.NEGATIVE_SENTIMENT_COLOR
    )
    neutral_patch = plt.Rectangle((0, 0), 1, 1, fc=ReportConfig.NEUTRAL_SENTIMENT_COLOR)

    ax.legend(
        # title="Sentimento",
        handles=[positive_patch, negative_patch, neutral_patch],
        labels=["Positivo", "Negativo", "Neutro"],
        bbox_to_anchor=(0.5, 1.1),
        loc="upper center",
        edgecolor="1",
        ncols=3,
    )

    st.pyplot(fig)

    st.markdown(
        """
        O ranking completo de avalia√ß√µes por empresa pode ser visualizado no
        menu <a target="_self" href="./Ranking_geral_de_avalia√ß√µes">ü•áRanking
        geral de avalia√ß√µes</a>.
    """,
        unsafe_allow_html=True,
    )


def company_analisys():
    st.subheader("Sentimentos das Avalia√ß√µes por Empresa")

    st.markdown(
        """
    A visualiza√ß√£o da distribui√ß√£o de avalia√ß√µes e emo√ß√µes em todas as empresas permite uma compara√ß√£o r√°pida e uma vis√£o abrangente do panorama geral.
"""
    )

    reviews_df = st.session_state.get("reviews_df")

    fig, ax = plt.subplots(1, figsize=(12, 6))
    sns.countplot(
        data=reviews_df,
        x="company",
        hue="predicted_sentiment",
        order=reviews_df["company"].value_counts().index,
        ax=ax,
        palette=ReportConfig.SENTIMENT_PALETTE,
    )

    for p in ax.patches:
        ax.annotate(
            f"{int(p.get_height())}",
            (p.get_x() + p.get_width() / 2.0, p.get_height()),
            ha="center",
            va="center",
            fontsize=6,
            color="black",
            xytext=(0, 5),
            textcoords="offset points",
        )

    sns.despine(bottom=False, left=True)

    plt.title(
        "Sentimentos das Avalia√ß√µes por Empresa",
        fontdict={
            "weight": "bold",
            "size": ReportConfig.CHART_TITLE_FONT_SIZE,
        },
    )

    plt.xlabel("")
    plt.ylabel("")

    plt.xticks(rotation=45, ha="right")
    plt.yticks([])

    plt.legend(title="Sentimento", labels=ReportConfig.SENTIMENT_DICT.values())

    st.pyplot(fig)


def sentiment_reviews_along_time():
    st.subheader("Quantidade de avalia√ß√µes por sentimento ao longo do tempo")

    st.markdown(
        """
    O gr√°fico apresenta uma an√°lise de sentimentos das avalia√ß√µes entre 05 de outubro de 2014 e 16 de mar√ßo de 2024.

    - As avalia√ß√µes positivas superam consistentemente as negativas ao longo do per√≠odo analisado, enquanto as avalia√ß√µes neutras s√£o menos frequentes.
    - Entre 2014 e 2017, h√° uma tend√™ncia ascendente nas avalia√ß√µes, seguida por um decl√≠nio que se repete de 2017 a 2020.
    - De 2020 a 2022, h√° um aumento expressivo na quantidade de avalia√ß√µes em todas as categorias, atingindo um pico em 2022.
    - Ap√≥s 2022, as avalia√ß√µes neutras come√ßam a declinar, acompanhadas por uma diminui√ß√£o nas avalia√ß√µes positivas.
    Em contrapartida, as avalia√ß√µes negativas seguem uma tend√™ncia de aumento, seguida por uma queda no in√≠cio de 2024, assim como as demais categorias.
"""
    )

    reviews_df = st.session_state.get("reviews_df")

    reviews_df["review_date"] = pd.to_datetime(
        reviews_df["review_date"], format="%Y-%m-%d"
    )
    reviews_df["year"] = reviews_df["review_date"].dt.year

    sentiment_counts = (
        reviews_df.groupby(["year", "predicted_sentiment"])
        .size()
        .reset_index(name="count")
    )

    fig, ax = plt.subplots(1, figsize=(12, 6))
    sns.lineplot(
        data=sentiment_counts,
        x="year",
        y="count",
        hue="predicted_sentiment",
        palette=ReportConfig.SENTIMENT_PALETTE,
        ax=ax,
    )

    # Annotations for number of reviews per sentiment
    years_unique = sentiment_counts["year"].unique()
    for year in years_unique:
        year_counts = sentiment_counts[sentiment_counts["year"] == year][
            "count"
        ].tolist()

        neutral_counts, positive_counts, negative_counts = (year_counts + [None] * 3)[
            :3
        ]

        if neutral_counts:
            ax.text(
                x=year,
                y=neutral_counts - 8,
                s=f"{neutral_counts}",
                ha="center",
                color=ReportConfig.NEUTRAL_SENTIMENT_COLOR,
            )

        if positive_counts:
            ax.text(
                x=year,
                y=positive_counts + 8,
                s=f"{positive_counts}",
                ha="center",
                color=ReportConfig.POSITIVE_SENTIMENT_COLOR,
            )

        if negative_counts:
            ax.text(
                x=year,
                y=negative_counts - 8,
                s=f"{negative_counts}",
                ha="center",
                color=ReportConfig.NEGATIVE_SENTIMENT_COLOR,
            )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    # ax.spines["bottom"].set_visible(False)

    ax.set_xlabel("Ano")
    ax.set_ylabel("Quantidade de avalia√ß√µes")

    ax.set_title(
        "Quantidade de avalia√ß√µes por sentimento ao longo do tempo",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.1,
    )

    handles, labels = ax.get_legend_handles_labels()
    for i in range(len(ReportConfig.SENTIMENT_DICT)):
        handles[i]._label = ReportConfig.SENTIMENT_DICT[int(labels[i])]

    plt.legend(
        # title="Sentimento",
        bbox_to_anchor=(0.5, 1.1),
        loc="upper center",
        edgecolor="1",
        ncols=3,
    )

    st.pyplot(fig)

    st.markdown(
        """
        As avalia√ß√µes ao longo do tempo por empresa podem ser visualizadas no
        menu <a target="_self" href="./Avalia√ß√µes_ao_longo_do_tempo">
        üìâAvalia√ß√µes ao longo do tempo</a>.
    """,
        unsafe_allow_html=True,
    )


def rating_star_analysis():
    warnings.filterwarnings("ignore", "use_inf_as_na")
    reviews_df = st.session_state.get("reviews_df")

    st.subheader(
        "Distribui√ß√£o de Sentimentos por Quantidade de Estrelas em Avalia√ß√µes, por Empresa"
    )

    st.markdown(
        """
    Esta an√°lise mostra padr√µes interessantes na rela√ß√£o entre as avalia√ß√µes e o n√∫mero de estrelas atribu√≠das, revelando correla√ß√µes intrigantes entre a satisfa√ß√£o dos funcion√°rios e a classifica√ß√£o geral.
"""
    )

    g = sns.FacetGrid(
        reviews_df,
        col="company",
        hue="predicted_sentiment",
        col_wrap=4,
    )
    g.map(sns.histplot, "star_rating")

    g.set_titles("{col_name}")
    g.set_axis_labels("Star Rating", "Count")
    g.add_legend(
        title="Predicted Sentiment",
        labels=list(ReportConfig.SENTIMENT_DICT.values()),
    )

    st.pyplot(g)


def rating_star_analysis2():
    reviews_df = st.session_state.get("reviews_df")

    st.subheader(
        "Distribui√ß√£o de Sentimentos por Quantidade de Estrelas em Avalia√ß√µes, por Empresa"
    )

    st.markdown(
        """
        Esta an√°lise mostra padr√µes interessantes na rela√ß√£o entre as avalia√ß√µes e o n√∫mero de estrelas atribu√≠das, revelando correla√ß√µes intrigantes entre a satisfa√ß√£o dos funcion√°rios e a classifica√ß√£o geral.
    """
    )

    company = st.selectbox(
        label="Empresa",
        options=reviews_df["company"].unique().tolist(),
        key="rating_star_company_input",
    )

    filtered_df = reviews_df[reviews_df["company"] == company][
        [
            "company",
            "employee_role",
            "employee_detail",
            "review_text",
            "review_date",
            "star_rating",
            "predicted_sentiment",
            "sentiment_label",
        ]
    ]
    filtered_df.reset_index(drop=True, inplace=True)

    sentiment_counts = (
        filtered_df.groupby(["company", "star_rating", "predicted_sentiment"])
        .size()
        .reset_index(name="count")
    )

    fig, ax = plt.subplots(1, figsize=(12, 8))

    sns.scatterplot(
        data=sentiment_counts,
        x="star_rating",
        y="count",
        hue="predicted_sentiment",
        # style="company",
        ax=ax,
        palette=sns.color_palette(),
    )

    plt.title(
        "Sentiment Counts by Star Rating and Company",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
    )
    plt.xlabel("Star Rating")
    plt.ylabel("Count")

    plt.xticks(ticks=sorted(reviews_df["star_rating"].unique()))

    handles, labels = ax.get_legend_handles_labels()
    handles[0].set_color([ReportConfig.NEGATIVE_SENTIMENT_COLOR])
    handles[1].set_color([ReportConfig.POSITIVE_SENTIMENT_COLOR])
    handles[2].set_color([ReportConfig.NEUTRAL_SENTIMENT_COLOR])

    legend_labels = [
        ReportConfig.SENTIMENT_DICT[i] for i in range(len(ReportConfig.SENTIMENT_DICT))
    ]

    plt.legend(
        title="Sentiment",
        labels=legend_labels,
        bbox_to_anchor=(1.05, 1),
        loc="upper left",
    )

    st.pyplot(fig)

    st.write("Avalia√ß√µes filtradas")
    filtered_df = filtered_df.drop(labels="predicted_sentiment", axis=1)
    st.dataframe(filtered_df)


def rating_star_analysis3():
    reviews_df = st.session_state.get("reviews_df")
    reviews_df = create_predicted_sentiment_plot(reviews_df)

    st.subheader("Distribui√ß√£o de sentimentos por quantidade de estrelas")

    st.markdown(
        """
        Este gr√°fico ilustra que:
        - As avalia√ß√µes de 1 a 3 estrelas apresentam um sentimento
        predominantemente negativo.
        - Por outro lado, as avalia√ß√µes de 4 estrelas mostram uma distribui√ß√£o
        equilibrada entre sentimentos positivos e negativos.
        - J√° as avalia√ß√µes de 5 estrelas s√£o majoritariamente positivas,
        destacando-se tamb√©m um n√∫mero significativo de avalia√ß√µes neutras.

        Essa predomin√¢ncia de avalia√ß√µes neutras em avalia√ß√µes de 5 estrelas
        pode ser atribu√≠da √† exig√™ncia no Glassdoor de preencher as se√ß√µes
        *Pr√≥s* e *Contras*. Em diversas avalia√ß√µes, os usu√°rios n√£o encontram
        aspectos negativos a serem mencionados na se√ß√£o *Contras*, resultando
        em coment√°rios como `N√£o h√° nada a ser apontado` ou `N√£o tenho nada a
        reclamar`.
    """
    )

    filtered_df = reviews_df[
        [
            "company",
            "employee_role",
            "employee_detail",
            "review_text",
            "review_date",
            "star_rating",
            "predicted_sentiment_plot",
            "sentiment_label",
        ]
    ]

    filtered_df.reset_index(drop=True, inplace=True)

    if len(filtered_df) > 0:
        sentiment_counts = (
            filtered_df.groupby(["star_rating", "predicted_sentiment_plot"])
            .size()
            .reset_index(name="count")
        )

        fig, ax = plt.subplots(1, figsize=(10, 6))

        bars = sns.barplot(
            data=sentiment_counts,
            x="star_rating",
            y="count",
            hue="predicted_sentiment_plot",
            ax=ax,
            palette=[
                ReportConfig.POSITIVE_SENTIMENT_COLOR,
                ReportConfig.NEGATIVE_SENTIMENT_COLOR,
                ReportConfig.NEUTRAL_SENTIMENT_COLOR,
            ],
        )

        for p in bars.patches:
            height = p.get_height()
            if math.isnan(height):
                height = 0.0

            bars.annotate(
                text=f"{int(height)}",
                xy=(p.get_x() + p.get_width() / 2.0, height),
                ha="center",
                va="center",
                fontsize=10,
                color="black",
                xytext=(0, 5),
                textcoords="offset points",
            )

        ax.set_title(
            "Distribui√ß√£o de sentimentos por quantidade de estrelas",
            fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
            y=1.1,
        )

        ax.set_xlabel("")
        ax.set_xticklabels(
            ["\u2605" * int(x) for x in sentiment_counts["star_rating"].unique()]
        )

        ax.set_yticks([])
        ax.set_ylabel("")

        ax.spines["top"].set_visible(False)
        ax.spines["right"].set_visible(False)
        ax.spines["left"].set_visible(False)

        positive_patch = plt.Rectangle(
            (0, 0), 1, 1, fc=ReportConfig.POSITIVE_SENTIMENT_COLOR
        )
        negative_patch = plt.Rectangle(
            (0, 0), 1, 1, fc=ReportConfig.NEGATIVE_SENTIMENT_COLOR
        )
        neutral_patch = plt.Rectangle(
            (0, 0), 1, 1, fc=ReportConfig.NEUTRAL_SENTIMENT_COLOR
        )

        ax.legend(
            # title="Sentimento",
            handles=[positive_patch, negative_patch, neutral_patch],
            labels=["Positivo", "Negativo", "Neutro"],
            bbox_to_anchor=(0.5, 1.1),
            loc="upper center",
            edgecolor="1",
            ncols=3,
        )

        st.pyplot(fig)
    else:
        st.error(
            AppMessages.ERROR_EMPTY_DATAFRAME,
            icon="üö®",
        )

    st.markdown(
        """
        A distribui√ß√£o de sentimentos por quantidades de estrelas para cada
        empresa pode ser visualizada no menu
        <a target="_self" href="./Avalia√ß√µes_por_quantidade_de_estrelas">
        üìäAvalia√ß√µes por quantidade de estrelas</a>.
    """,
        unsafe_allow_html=True,
    )


def wordcloud_analysis():
    st.subheader("Word Cloud de todas as avalia√ß√µes")

    st.markdown(
        """
    A Nuvem de Palavras √© uma representa√ß√£o visual que ilustra as palavras
    mais frequentemente utilizadas no conjunto de avalia√ß√µes. Neste
    gr√°fico, as palavras aparecem em tamanhos variados, refletindo sua
    frequ√™ncia de uso: quanto maior a palavra, mais vezes ela foi mencionada
    nas avalia√ß√µes.

    √â importante ressaltar que as stopwords, que s√£o palavras comuns e
    geralmente sem significado relevante para a an√°lise (como "e", "a", "o",
    "de"), foram exclu√≠das desta visualiza√ß√£o. Al√©m disso, a palavra `empresa`
    foi removida, pois sua alta frequ√™ncia n√£o contribui para a compreens√£o
    dos temas e sentimentos expressos nas avalia√ß√µes.

    Essa abordagem permite uma an√°lise mais clara e focada, facilitando a
    identifica√ß√£o r√°pida dos t√≥picos mais relevantes e das percep√ß√µes
    predominantes dos usu√°rios.
"""
    )

    reviews_df = st.session_state.get("reviews_df")
    review_text = reviews_df["review_text"].str.split().values.tolist()
    corpus = [word for i in review_text for word in i]

    non_stopwords_corpus = []
    for word in corpus:
        word_lower = word.lower()
        cleaned_word = word_lower.translate(TRANSLATION_TABLE_SPECIAL_CHARACTERS)
        if cleaned_word and cleaned_word not in STOPWORDS:
            non_stopwords_corpus.append(cleaned_word)

    non_stopwords_corpus_str = " ".join(non_stopwords_corpus)

    wordcloud = WordCloud(
        background_color="white",
        random_state=ReportConfig.RANDOM_SEED,
        max_words=50,
        width=1024,
        height=768,
    )

    fig, ax = plt.subplots(1, figsize=(10, 6))
    plt.axis("off")

    ax.imshow(wordcloud.generate(str(non_stopwords_corpus_str)))

    st.pyplot(fig)

    st.markdown(
        """
        A Word Cloud de avalia√ß√µes por sentimento e por empresa pode ser
        visualizada no menu
        <a target="_self" href="./Word_Clouds">‚òÅÔ∏èWord Clouds</a>.
    """,
        unsafe_allow_html=True,
    )


def most_common_words_analysis():
    st.subheader("Top 10 palavras mais frequentes nas avalia√ß√µes")

    st.markdown(
        """
        Embora a Word Cloud ofere√ßa uma vis√£o geral interessante das
        palavras mais utilizadas nas avalia√ß√µes, ela pode n√£o ser a melhor
        op√ß√£o para destacar de forma clara e precisa a palavra mais frequente.
        Para complementar essa an√°lise, √© mostrado o gr√°fico de barras que
        apresenta as 10 palavras mais frequentemente utilizadas nas avalia√ß√µes
        analisadas.

        Este gr√°fico segue os mesmos crit√©rios da Word Cloud, garantindo que
        as palavras selecionadas sejam relevantes e significativas. Com a
        disposi√ß√£o em barras, √© poss√≠vel visualizar facilmente a frequ√™ncia de
        cada palavra, permitindo uma compara√ß√£o direta entre elas.

        Essa abordagem torna a interpreta√ß√£o dos dados mais intuitiva e
        acess√≠vel, facilitando a identifica√ß√£o dos temas mais recorrentes nas
        avalia√ß√µes.
"""
    )

    reviews_df = st.session_state.get("reviews_df")
    review_text = reviews_df["review_text"].str.split().values.tolist()
    corpus = [word for i in review_text for word in i]

    non_stopwords_corpus = []
    for word in corpus:
        word_lower = word.lower()
        cleaned_word = word_lower.translate(TRANSLATION_TABLE_SPECIAL_CHARACTERS)
        if cleaned_word and cleaned_word not in STOPWORDS:
            non_stopwords_corpus.append(cleaned_word)

    counter = Counter(non_stopwords_corpus)
    most_common_words = counter.most_common(n=10)

    words, counts = zip(*most_common_words)  # Unzip the words and counts
    most_common_words_df = pd.DataFrame({"words": words, "counts": counts})

    fig, ax = plt.subplots(1, figsize=(10, 8))

    sns.barplot(
        data=most_common_words_df,
        x="counts",
        y="words",
        ax=ax,
        width=0.9,
        orient="h",
    )

    # Annotates
    for p in ax.patches:
        ax.annotate(
            text=f"{p.get_width():.0f}",
            xy=(p.get_width(), (p.get_y() + p.get_height() / 2)),
            ha="center",
            va="center",
            fontsize=10,
            color="white",
            xytext=(-15, 0),
            textcoords="offset points",
        )

    # Axes config
    ax.set_xlabel("")

    ax.set_xticks([])

    ax.set_ylabel("")

    ax.set_title(
        "Top 10 palavras mais frequentes nas avalia√ß√µes",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.0,
    )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)

    st.pyplot(fig)

    st.markdown(
        """
        As Top 10 palavras mais frequentes nas avalia√ß√µes por empresa e por
        sentimento pode ser visualizado no menu <a target="_self" href="./Top_10_palavras_mais_usadas">üìäTop 10 palavras mais frequentes</a>.
    """,
        unsafe_allow_html=True,
    )


def ngram_analysis():
    st.subheader("Top 10 NGrams mais frequentes nas avalia√ß√µes")

    st.markdown(
        """
    Embora o gr√°fico de palavras mais frequentes forne√ßa uma vis√£o inicial
    sobre os termos mais utilizados nas avalia√ß√µes, ele n√£o captura a riqueza
    dos contextos em que essas palavras aparecem. Palavras isoladas podem ter
    significados variados e n√£o revelam como elas se combinam para formar
    ideias ou sentimentos mais complexos. Por exemplo, a palavra `crescimento`
    pode aparecer frequentemente, mas sem o contexto, como em `oportunidade de
    crescimento`, seu significado pode ser amb√≠guo.

    Os n-gramas, que s√£o sequ√™ncias cont√≠guas de "n" itens (palavras ou
    caracteres), s√£o essenciais para uma an√°lise mais profunda, pois permitem
    identificar padr√µes e temas recorrentes nas avalia√ß√µes.

    Ao considerar as combina√ß√µes de palavras, conseguimos entender melhor as
    percep√ß√µes dos funcion√°rios e os aspectos mais relevantes de suas
    experi√™ncias. Essa an√°lise revelou que as combina√ß√µes de palavras mais
    frequentes, considerando todas as avalia√ß√µes, foram: `ambiente de
    trabalho`, `plano de carreira`, `plano de sa√∫de` e `oportunidade de
    crescimento`.
"""
    )

    reviews_df = st.session_state.get("reviews_df")

    review_text = reviews_df["review_text"]

    vec = CountVectorizer(ngram_range=(3, 3)).fit(review_text)
    bag_of_words = vec.transform(review_text)
    sum_words = bag_of_words.sum(axis=0)

    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]
    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)

    top_n_grams = words_freq[:10]
    x, y = map(list, zip(*top_n_grams))

    fig, ax = plt.subplots(1, figsize=(10, 8))

    sns.barplot(
        x=y,
        y=x,
        ax=ax,
        width=0.9,
        orient="h",
    )

    # Annotates
    for p in ax.patches:
        ax.annotate(
            text=f"{p.get_width():.0f}",
            xy=(p.get_width(), (p.get_y() + p.get_height() / 2)),
            ha="center",
            va="center",
            fontsize=11,
            color="white",
            xytext=(-15, 0),
            textcoords="offset points",
        )

    # Axes config
    ax.set_xlabel("")

    ax.set_xticks([])

    ax.set_ylabel("")

    ax.set_title(
        "Top 10 NGrams mais frequentes nas avalia√ß√µes",
        fontsize=ReportConfig.CHART_TITLE_FONT_SIZE,
        y=1.0,
    )

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_visible(False)

    st.pyplot(fig)

    st.markdown(
        """
        Os Top 10 NGrams mais frequentes nas avalia√ß√µes por empresa pode ser
        visualizado no menu <a target="_self" href="./NGrams">üî†NGrams</a>.
    """,
        unsafe_allow_html=True,
    )


def conclusion():
    st.subheader("Conclus√£o")

    st.markdown(
        """
    **A an√°lise de sentimentos das avalia√ß√µes no Glassdoor de 22 empresas de
    Tecnologia em Cuiab√°** revelou que o modelo de IA, baseado na t√©cnica de
    Transfer Learning com BERTimbau, **demonstrou uma alta acur√°cia de 95% na
    classifica√ß√£o das avalia√ß√µes**, evidenciando a efic√°cia metodologia aplicada.

    Os resultados indicam que **15 das 22 empresas analisadas possuem mais
    avalia√ß√µes positivas do que negativas**, refletindo um ambiente de trabalho
    predominantemente favor√°vel.

    As **avalia√ß√µes positivas** frequentemente mencionam temas como **ambiente
    de trabalho**, **plano de sa√∫de** e **oportunidade de crescimento**,
    enquanto as **avalia√ß√µes negativas** destacam preocupa√ß√µes com **plano de
    carreira**, **sal√°rio abaixo do mercado** e, em alguns casos, o **plano de
    sa√∫de**. As **avalia√ß√µes neutras**, embora menos frequentes, sugerem que
    muitos colaboradores **n√£o encontraram aspectos negativos a serem
    destacados**, indicando uma satisfa√ß√£o geral com suas experi√™ncias.

    Al√©m disso, a an√°lise temporal revelou que **as avalia√ß√µes positivas sempre
    foram predominantes em rela√ß√£o as demais**. Esta an√°lise tamb√©m mostrou que
    houve um grande aumento no n√∫mero de avalia√ß√µes entre 2020 e 2022, per√≠odo
    da Pandemia de Covid-19, onde as empresas contrataram mais.

    Esses insights s√£o fundamentais para as empresas, pois proporcionam uma
    vis√£o clara das √°reas que precisam de melhorias e das que j√° est√£o
    apresentando resultados positivos. Com base nessas informa√ß√µes, as
    organiza√ß√µes podem desenvolver estrat√©gias eficazes para aprimorar o
    ambiente de trabalho, focar em benef√≠cios que realmente importam para os
    colaboradores e, assim, n√£o apenas aumentar a reten√ß√£o de talentos, mas
    tamb√©m atrair profissionais que buscam ambientes com melhores avalia√ß√µes.
    A reputa√ß√£o positiva, refletida nas avalia√ß√µes, pode ser um diferencial
    decisivo na escolha de uma empresa por candidatos qualificados, impactando
    diretamente o sucesso e a competitividade no mercado.
"""
    )


if __name__ == "__main__":
    warnings.filterwarnings("ignore", "use_inf_as_na")

    st.set_page_config(
        page_title="Home",
        page_icon=":house:",
    )

    st.markdown(
        ReportConfig.CUSTOM_CSS,
        unsafe_allow_html=True,
    )

    st.sidebar.warning(AppMessages.WARNING_PLOT_NOT_WORKING)

    st.header(
        "An√°lise de sentimentos nas avalia√ß√µes do Glassdoor: Um estudo sobre empresas de Tecnologia em Cuiab√°"
    )

    if "reviews_df" not in st.session_state:
        # Reviews DF
        reviews_df = pd.read_csv("./glassdoor_reviews_predicted.csv")

        reviews_df["sentiment"] = reviews_df["sentiment"].apply(
            lambda x: 2 if x == -1 else x
        )

        reviews_df["sentiment_label"] = reviews_df["predicted_sentiment"].map(
            ReportConfig.SENTIMENT_DICT
        )

        st.session_state["reviews_df"] = reviews_df

        # Top Companies Reviews DF
        top_positive_companies_df, top_negative_companies_df = (
            get_ranking_positive_negative_companies(reviews_df)
        )

        st.session_state["top_positive_companies_df"] = top_positive_companies_df
        st.session_state["top_negative_companies_df"] = top_negative_companies_df

    introduction()
    st.markdown("---")

    general_analysis()
    st.markdown("---")

    # company_analisys()

    positive_reviews_ranking()
    negative_reviews_ranking()
    st.markdown("---")

    sentiment_reviews_along_time()
    st.markdown("---")

    # rating_star_analysis()
    # rating_star_analysis2()

    rating_star_analysis3()
    st.markdown("---")

    wordcloud_analysis()
    st.markdown("---")

    most_common_words_analysis()
    st.markdown("---")

    ngram_analysis()
    st.markdown("---")

    conclusion()
